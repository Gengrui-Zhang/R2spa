---
title             : "Results and Discussion"

author: 
  - name          : "Jimmy"

bibliography      : "r-references.bib"

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
header-includes   :
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother

csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
documentclass     : "apa7"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
library(dplyr)
library(tidyr)
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(papaja)
library(stringr)

sim <- readRDS("/Users/jimmy_z/R Projects/R2spa/Sim_Data/Match_02262024.rds")
sim_results <- sim %>% 
  dplyr::select(-c(beta1, beta2, c(SIM_TIME:WARNINGS), REPLICATIONS)) %>%
  mutate(across(where(is.numeric), round, 4),
         cor_xm = ifelse(cor_xm == 0, "0", cor_xm))
```

The results of the interaction effect estimated by RAPI, matched-pair UPI, and 2S-PA-Int were summarized and compared in terms of the average raw bias, the standardized bias, the relative standard error (SE) bias with outlier proportions, the 95% CI coverage rate of the interaction effect, and the root mean square error (RMSE) over 2,000 replications. Detailed statistics are displayed in Table 1, 2, 3, and 4, respectively. For all simulation conditions, the matched-pair UPI and 2S-PA-Int methods successfully converged without producing any inadmissible results. Models with the RAPI method did not fully converge under 8 of the 27 conditions, particularly those with low reliability (rho = 0.7) and small sample size (N = 100), and had a range of 1% ~ 12% non-convergence rate. Subsequent analyses did not include the inadmissible solutions generated by the RAPI method. 

## Average Raw Bias and Standardized Bias for $\gamma_{xm}$

As delineated in Table 1, an examination of all simulation conditions revealed that the absolute values of both the average raw bias (B) and the standardized biases (SB) associated with the interaction effect estimate ($\gamma_{xm}$) using the three methods consistently remained below the predetermined acceptable threshold of .40 (B = .00 ~ .08; SB = -.04 ~ .25). A discernible pattern in the impact of the correlation between the two first-order latent predictors on $\gamma_{xm}$ was not identified. Regarding the influence of population reliability levels, all the methods demonstrated robustness to conditions of low reliability (i.e., $\rho = 0.7$). Notably, with an increase in population reliability levels, both the absolute SB and B exhibited declining trends across all the conditions with medium to high sample sizes (i.e., $\textit{N} = 250$ and $\textit{N} = 500$). For instance, when $\textit{N} = 250$ and $Corr(\xi_{x}, \xi_{m}) = 0$, the absolute SB and B for the RAPI method decreased from .21(.03) to .03(.00) as $\rho$ increased from .70 to .90. Similar decreasing trends were observable in the matched-pair UPI and 2S-PA-Int methods, where their absolute SB and B decreased from .08(.01) to .02(.00), and from 0.10 (.01) to .03(.00), respectively. As for $\textit{N} = 100$, the same trends were still observed in 2S-PA-Int while two exceptions appeared in RAPI and matched-pair UPI respectively. The absolute SB and B for RAPI first increased from .14(.08) to .18(.03) and then decreased to .08(.01) as $Corr[\xi_{x}, \xi_{xm}] = 0$, and those for matched-pair UPI first increased from .10(.03) to .11(.02) and then decreased to .03(.00) as $Corr[\xi_{x}, \xi_{xm}] = 0.6$.

The B values generally became smaller as sample size increased for the three methods, which aligned with the statistical property of SEM models such that larger sample sizes tend to provide more accurate and reliable parameter estimates and reduce sampling errors. Nevertheless this pattern was not exactly consistent with the absolute SB because the empirical standard deviation of B decreased as the sample size increased, which might amplify the absolute SB. For instance, when $\rho = .70$ and $Corr[\xi_{x}, \xi_{m}] = 0$, the magnitude of raw average biases decreased from .08 to .01 for RAPI while the absolute SB first increased from .14 to .21 and then decreased to .19. The above findings revealed that the pattern displayed through B values might be masked by the corresponding empirical standard deviation, and the comparability of raw average biases need to be cautiously considered in standard units.

It was found that the absolute SB of RAPI and matched-pair UPI were almost positive while some of the 2S-PA-Int estimates were negative across simulation conditions. The results were consistent with previous findings for RAPI and matched-pair UPI such that they tended to provide overestimated interaction estimates with high correlations between first-order latent predictors and low reliability (Marsh et al., 2004; Hsiao et al., 2018). 2S-PA-Int did not show a clear sign of over or underestimation, indicating that the absolute SB values were more randomly distributed. Nevertheless, all the methods yielded comparably low standardized biases across simulation conditions, which was acceptable for practical use. 

```{r standardized bias (raw bias), message=FALSE, warning=FALSE}
raw_bias <- sim_results %>%
  dplyr::select(N:raw_bias.tspa_yint_est) %>%
  dplyr::select(-beta3) %>%
  arrange(N) %>%
  relocate(cor_xm, .after = rel)
names(raw_bias) <- c("$\\textit{N}$", "$\\rho$", "$Corr(\\xi_{x}, \\xi_{m})$", "RAPI", "Matched-Pair UPI", "2SPA")

raw_bias_wide <- raw_bias %>%
  pivot_wider(names_from = `$\\rho$`,
              values_from = c("RAPI", "Matched-Pair UPI", "2SPA"), #
              names_prefix = "corr_") %>%
  mutate(`$\\textit{N}$` = ifelse(`$Corr(\\xi_{x}, \\xi_{m})$` != 0, " ", `$\\textit{N}$`),
         across(where(is.numeric), round, 2))
names(raw_bias_wide) <- c("$\\textit{N}$", "$Corr(\\xi_{x}, \\xi_{m})$", paste(rep(c("$\\rho = .70$", "$\\rho = .80$", "$\\rho = .90$"), 3)))

std_bias <- sim_results %>% 
  dplyr::select(N:rel, std_bias.rapi_yint_est:std_bias.tspa_yint_est) %>%
  dplyr::select(-beta3) %>%
  arrange(N) %>%
  relocate(cor_xm, .after = rel) 
names(std_bias) <- c("$\\textit{N}$", "$\\rho$", "$Corr(\\xi_{x}, \\xi_{m})$", "RAPI", "Matched-Pair UPI", "2SPA")

std_bias_wide <- std_bias %>%
  pivot_wider(names_from = `$\\rho$`,  
              values_from = c("RAPI", "Matched-Pair UPI", "2SPA"), #
              names_prefix = "corr_") %>%
  mutate(`$\\textit{N}$` = ifelse(`$Corr(\\xi_{x}, \\xi_{m})$` != 0, " ", `$\\textit{N}$`),
         across(where(is.numeric), round, 2))
names(std_bias_wide) <- c("$\\textit{N}$", "$Corr(\\xi_{x}, \\xi_{m})$", paste(rep(c("$\\rho = .70$", "$\\rho = .80$", "$\\rho = .90$"), 3)))

standardized_bias <- raw_bias_wide
for (col_idx in 3:ncol(raw_bias_wide)) {
  combined_values <- mapply(FUN = function(x, y) paste(y, "\ (", x, ")", sep = ""),
                            x = raw_bias_wide[, col_idx], y = std_bias_wide[, col_idx])
  standardized_bias[, col_idx] <- combined_values
}

standardized_bias_table <- apa_table(standardized_bias,
                                    escape = F,
                                    caption = "Standardized Bias (Average Raw Bias) for $\\gamma_{xm} (= 0.3)$ over 2000 Replications.",
                                    align = c(rep("c", ncol(standardized_bias))),
                                    col_spanners = list(`RAPI` = c(3, 5), `Matched-Pair UPI` = c(6, 8), `2S-PA-Int` = c(9, 11)),
                                    landscape = TRUE,
                                    font_size = "small",
                                    note = "$\\textit{N}$ = sample size; $Corr(\\xi_{x}, \\xi_{m})$ = correlation between $\\xi_{x}$ and $\\xi_{m}$; $\\rho$ = reliability level; RAPI = reliability-adjusted product indicator method; Matched-Pair UPI = matched-pair product unconstrained indicator method; 2S-PA-Int = two-stage path analysis with interaction method. Average raw bias are shown in pararenthese. Note that numerical values have been rounded to two decimal places for consistency, which means that some values, while very close to 0 but not exactly 0, are displayed as 0.")

standardized_bias_table
```

## Relative SE Bias of $\gamma_{xm}$

Table 2 showed the robust relative standard error (SE) bias ratio with outlier proportions of SE when $\gamma_{xm} = 0.3$. All the values outside the -10% ~ 10% range were bolded. Generally, the values of robust relative SE bias were all below 10% for RAPI, matched-pair UPI, and 2S-PA-Int across the conditions of medium to high reliability level. The ranges were from .56%(1.55%) to 8.33%(1.65%) for RAPI, .09%(1.55%) to -8.96%(5.85%) for matched-pair UPI, and -.57%(1.40%) to -7.39%(1.30%) for 2S-PA-Int, which implied that the estimated SE values of $\hat{\gamma}_{xm}$ were not biased and $\hat{\gamma}_{xm}$ estimated by the three methods under medium to high reliability showed less variability across other conditions. Compared to 2S-PA-Int, matched-pair UPI produced two relative SE values outside the acceptable range under the conditions of small sample size ($\textit{N} = 100$) and low reliability ($\rho = .70$): -11.52%(8.15%) and -14.14%(8.40%), meaning that the SE values were negatively biased. As for RAPI, unacceptable relative SE biases were generated across various conditions under low reliability ($\rho = .7$). The outlier proportions of SEs identified by the IQR method showed declining trends as sample size increased and reliability levels improved for all the methods, meaning that the estimation of $\gamma_{xm}$ became more accurate and stable with less extreme values. For instance, the proportion of outliers for RAPI decreased from 10.90% to 5.55% and to 2.60% under $\textit{N} = 100$ and $\rho = .70$, while within the condition of $\textit{N} = 100$ the proportion decreased from 10.90 to 5.40 to 1.90 as $\rho$ increased. 

However, the robust relative SE bias did not demonstrate a clear pattern associated with the population reliability value and sample size for the three methods. It was found that even though under the condition of large sample size and high reliability, the relative SE bias could be higher then those under worse conditions. For example, when $\textit{N} = 500$ and $\rho = .90$, the relative SE bias produced by 2S-PA-Int was -2.41%, while the value was -1.02 under $\textit{N} = 100$ and $\rho = .90$. It implied that the estimated SEs were unstably deviated from the true reference value (i.e., empirical standard deviation of $\gamma_{xm}$). Additionally, the overall values of the relative SE bias were negative for matched-pair UPI and 2S-PA-Int, and almost positive for RAPI, which indicated that the SEs were systematically underestimated for matched-pair UPI and 2S-PA-Int but overestimated for RAPI. 

```{r MAD relative SE bias with outliers proportion, message=FALSE, warning=FALSE}
MAD <- sim_results %>% 
  dplyr::select(N:rel, stdMed_rse_bias.rapi_yint_se:stdMed_rse_bias.tspa_yint_se) %>%
  dplyr::select(-beta3) %>%
  arrange(N) %>%
  relocate(cor_xm, .after = rel) %>%
  mutate(stdMed_rse_bias.rapi_yint_se = stdMed_rse_bias.rapi_yint_se*100,
         stdMed_rse_bias.upi_yint_se = stdMed_rse_bias.upi_yint_se*100,
         stdMed_rse_bias.tspa_yint_se = stdMed_rse_bias.tspa_yint_se*100)
names(MAD) <- c("$\\textit{N}$", "$\\rho$", "$Corr(\\xi_{x}, \\xi_{m})$", "RAPI", "Matched-Pair UPI", "2SPA")

MAD_wide <- MAD %>%
  pivot_wider(names_from = `$\\rho$`,  
              values_from = c("RAPI", "Matched-Pair UPI", "2SPA"), #
              names_prefix = "corr_") %>%
  mutate(`$\\textit{N}$` = ifelse(`$Corr(\\xi_{x}, \\xi_{m})$` != 0, " ", `$\\textit{N}$`))
names(MAD_wide) <- c("$\\textit{N}$", "$Corr(\\xi_{x}, \\xi_{m})$", paste(rep(c("$\\rho = .70$", "$\\rho = .80$", "$\\rho = .90$"), 3)))

outlier_se <- sim_results %>% 
  dplyr::select(N:rel, outlier_se.rapi_yint_se:outlier_se.tspa_yint_se) %>%
  dplyr::select(-beta3) %>%
  arrange(N) %>%
  relocate(cor_xm, .after = rel) %>%
  mutate(across(where(is.numeric), ~sprintf("%.2f", .)))
  
names(outlier_se) <- c("$\\textit{N}$", "$\\rho$", "$Corr(\\xi_{x}, \\xi_{m})$", "RAPI", "Matched-Pair UPI", "2SPA")

outlier_se_wide <- outlier_se %>%
  pivot_wider(names_from = `$\\rho$`,  
              values_from = c("RAPI", "Matched-Pair UPI", "2SPA"), #
              names_prefix = "corr_") %>%
  mutate(`$\\textit{N}$` = ifelse(`$Corr(\\xi_{x}, \\xi_{m})$` != 0, " ", `$\\textit{N}$`)) 
names(outlier_se_wide) <- c("$\\textit{N}$", "$Corr(\\xi_{x}, \\xi_{m})$", paste(rep(c("$\\rho = .70$", "$\\rho = .80$", "$\\rho = .90$"), 3)))

MAD_bias <- MAD_wide
for (col_idx in 3:ncol(MAD_wide)) {
  combined_values <- mapply(FUN = function(x, y) paste(y, "\ (", x, ")", sep = ""),
                            x = outlier_se_wide[, col_idx], y = MAD_wide[, col_idx])
  MAD_bias[, col_idx] <- combined_values
}

bold_if_larger_than_10 <- function(cell) {
  first_number <- as.numeric(str_extract(cell, "^[^\\(]+"))
  if (!is.na(first_number) && abs(first_number) > 10) {
    return(sprintf("\\textbf{%s}", cell))
  } else {
    return(cell)
  }
}

for (i in 3:ncol(MAD_bias)) {
  # Applying the formatting function to each element of the column
  MAD_bias[[i]] <- sapply(MAD_bias[[i]], bold_if_larger_than_10)
}

MAD_bias_table <- apa_table(MAD_bias, 
            escape = F,
            caption = "Robust Relative Standard Error (SE) Bias Ratio (Outlier Proportion of SE; $\\%$) for $\\gamma_{xm} (= 0.3)$ over 2000 Replications.",
            align = c(rep("c", ncol(MAD_bias))),
            col_spanners = list(`RAPI` = c(3, 5), `Matched-Pair UPI` = c(6, 8), `2S-PA-Int` = c(9, 11)),
            landscape = TRUE,
            font_size = "footnotesize",
            note = "$\\textit{N}$ = sample size; $Corr(\\xi_{x}, \\xi_{m})$ = correlation between $\\xi_{x}$ and $\\xi_{m}$; $\\rho$ = reliability level; RAPI = reliability-adjusted product indicator method; Matched-Pair UPI = matched-pair product unconstrained indicator method; 2S-PA-Int = two-stage path analysis with interaction method. Outlier proportions of SE are shown in parenthese and all the numbers were percentages. Note that relative SE bias values outside the acceptable range of [-10$\\%$, 10$\\%$] are bolded.")
MAD_bias_table
```

## Coverage Rate of 95% CI of $\gamma_{xm}$

```{r coverage rate, message=FALSE, warning=FALSE}
coverage <- sim_results %>% 
  dplyr::select(N:rel, coverage.rapi_yint_est:coverage.tspa_yint_est) %>%
  dplyr::select(-beta3) %>%
  arrange(N) %>%
  relocate(cor_xm, .after = rel) %>%
  mutate(coverage.rapi_yint_est = coverage.rapi_yint_est*100,
         coverage.upi_yint_est = coverage.upi_yint_est*100,
         coverage.tspa_yint_est = coverage.tspa_yint_est*100) 
names(coverage) <- c("$\\textit{N}$", "$\\rho$", "$Corr(\\xi_{x}, \\xi_{m})$", "RAPI", "Matched-Pair UPI", "2SPA")

coverage_wide <- coverage %>%
  pivot_wider(names_from = `$\\rho$`,  
              values_from = c("RAPI", "Matched-Pair UPI", "2SPA"), #
              names_prefix = "corr_") %>%
  mutate(`$\\textit{N}$` = ifelse(`$Corr(\\xi_{x}, \\xi_{m})$` != 0, " ", `$\\textit{N}$`))
names(coverage_wide) <- c("$\\textit{N}$", "$Corr(\\xi_{x}, \\xi_{m})$", paste(rep(c("$\\rho = .70$", "$\\rho = .80$", "$\\rho = .90$"), 3)))

bold_if_less_than_91 <- function(cell) {
  if (!is.na(cell) && abs(cell) < 91) {
    return(sprintf("\\textbf{%s}", cell))
  } else {
    return(cell)
  }
}

for (i in 3:ncol(coverage_wide)) {
  # Applying the formatting function to each element of the column
  coverage_wide[[i]] <- sapply(coverage_wide[[i]], bold_if_less_than_91)
}

coverage_table <- apa_table(coverage_wide, 
            escape = F,
            caption = "95 $\\%$ Confidence Interval (CI) Coverage Rate for $\\gamma_{xm} (= 0.3)$ over 2000 Replications.",
            align = c(rep("c", ncol(coverage))),
            col_spanners = list(`RAPI` = c(3, 5), `Matched-Pair UPI` = c(6, 8), `2S-PA-Int` = c(9, 11)),
            landscape = TRUE,
            font_size = "small",
            note = "$\\textit{N}$ = sample size; $Corr(\\xi_{x}, \\xi_{m})$ = correlation between $\\xi_{x}$ and $\\xi_{m}$; $\\rho$ = reliability level; RAPI = reliability-adjusted product indicator method; Matched-Pair UPI = matched-pair product unconstrained indicator method; 2S-PA-Int = two-stage path analysis with interaction method. Coverage rates not reaching the acceptable threshold of 91$\\%$ are bolded.")

coverage_table
```

As shown in Table 3, the coverage rates of 95$\%$ CI were adequately within the acceptable range (91 - 98%) for RAPI and 2S-PA-Int across all the simulation conditions, with a range from 95.50% to 97.75% for RAPI and 93.10% to 95.50% for 2S-PA-Int. For UPI, three values that occurred under the condition of small sample size ($\textit{N} = 100$) and low reliability level ($\rho = .70$) were beyond the acceptable range: 87.9%, 88.75%, and 89.65%; Nevertheless, the lowest coverage only showed a 2.1% gap to 91%. 
No clear trends of coverage rate were observed in terms of the sample size, the population reliability level, and the correlation between first-order latent variables within the methods. However, across the methods, it was observed that generally RAPI demonstrated the highest coverage rate, followed by 2S-PA-Int with the second highest, and UPI exhibiting the lowest coverage rate. This order revealed that the RAPI method had the highest chance of capturing the true interaction effect with 2S-PA-Int and UPI followed, when the true interaction effect existed. 

## RMSE of $\gamma_{xm}$

```{r rmse, message=FALSE, warning=FALSE}
rmse <- sim_results %>% 
  dplyr::select(N:rel, rmse.rapi_yint_est:rmse.tspa_yint_est) %>%
  dplyr::select(-beta3) %>%
  arrange(N) %>%
  relocate(cor_xm, .after = rel)
names(rmse) <- c("$\\textit{N}$", "$\\rho$", "$Corr(\\xi_{x}, \\xi_{m})$", "RAPI", "Matched-Pair UPI", "2S-PA-Int")

rmse_wide <- rmse %>%
  pivot_wider(names_from = `$\\rho$`,  
              values_from = c("RAPI", "Matched-Pair UPI", "2S-PA-Int"), #
              names_prefix = "corr_") %>%
  mutate(`$\\textit{N}$` = ifelse(`$Corr(\\xi_{x}, \\xi_{m})$` != 0, " ", `$\\textit{N}$`))
names(rmse_wide) <- c("$\\textit{N}$", "$Corr(\\xi_{x}, \\xi_{m})$", paste(c("rapi.$\\rho = .70$", "rapi.$\\rho = .80$", "rapi.$\\rho = .90$", "upi.$\\rho = .70$", "upi.$\\rho = .80$", "upi.$\\rho = .90$", "2spa.$\\rho = .70$", "2spa.$\\rho = .80$", "2spa.$\\rho = .90$")))

rmse_wide <- rmse_wide %>%
  select(1, 2, 3, 6, 9, 4, 7, 10, 5, 8, 11)
names(rmse_wide) <- c("$\\textit{N}$", "$Corr(\\xi_{x}, \\xi_{m})$", paste(rep(c("RAPI", "Matched-Pair UPI", "2S-PA-Int") ,3)))

rmse_table <- apa_table(rmse_wide, 
            escape = F,
            caption = "Root Mean Square Error (RMSE) for $\\gamma_{xm} (= 0.3)$ over 2000 Replications.",
            align = c(rep("c", ncol(rmse))),
            col_spanners = list(`$\\rho = .70$` = c(3, 5), `$\\rho = .80$` = c(6, 8), `$\\rho = .90$` = c(9, 11)),
            landscape = TRUE,
            font_size = "footnotesize",
            note = "$\\textit{N}$ = sample size; $Corr(\\xi_{x}, \\xi_{m})$ = correlation between $\\xi_{x}$ and $\\xi_{m}$; $\\rho$ = reliability level; RAPI = reliability-adjusted product indicator method; Matched-Pair UPI = matched-pair product unconstrained indicator method; 2S-PA-Int = two-stage path analysis with interaction method. Note that the methods are grouped in the second-order header for comparing RMSE under the same conditions.")

rmse_table
```

Table 4 showed that the RMSE values for $\gamma_{xm}$ decreased as the sample size increased and the reliability level increased. Comparing RMSE across methods, 2S-PA-Int showed the least (or equally least) RMSE values across all the simulation conditions, indicating that 2S-PA-Int had a closer fit of to the data and more accurate estimation of the true $\gamma_{xm}$. For example, under the small sample size and low reliability, the RMSE values of 2S-PA-Int ranged from .20 to .32 while those of RAPI and matched-pair UPI ranged from .25 to .61 and .34 to .39 respectively. However, note that the differences on RMSE across the methods became less obvious under the condition of high reliability ($\rho = .90$), meaning that all the methods tended to produce more accurate and less unstable estimations of the interaction effect. 

## Discussion

Applied researchers often focus on complex relationships between variables, such as interactions. However, classical regression models, which assume variables are free of measurement error, have been shown to produce biased estimates. Consequently, latent variables approaches with the SEM framework are increasingly being considered. In this study, we reviewed and compared the performance of matched-pair UPI and RAPI with 2S-PA-Int in estimating interaction effects on congeneric items with varying factor loadings and errors.

We extended the 2S-PA model by Lai and Hsiao (2021) to support the latent interaction estimation, namely 2S-PA-Int.
The major difference between the three methods is on the formation of the latent interaction term. Specifically, matched-pair UPI forms the latent interaction term by using multiple product indicators generated by first-order indicators, and thus it is a multiple-indicator method. Instead, RAPI and 2S-PA use composite scores and factor scores as single indicators to the latent interaction term, respectively. Our findings indicated that all three methods were capable of generating unbiased estimates of interaction effects by accounting for measurement errors, with all the absolute SB and B values estimates falling below the .40 threshold. Notably, RAPI and UPI exhibited substantially positive SB values, suggesting a tendency to overestimate interaction effects when true effects are present. These observations align with the results from Marsh et al. (2004) using items with congeneric factors (i.e., only factor loadings were varied), Hsiao et al. (2018) using tau-equivalent items (i.e., only error variances were varied), and Hsiao et al. (2021) using congeneric items, where matched-pair UPI and RAPI slightly overestimated interaction coefficients when true interaction effects were nonzero, albeit to an acceptable degree. Our results echoed that RAPI and matched-pair UPI should be used with caution when researchers prefer to be more conservative with estimated effects. 

Higher coverage rates with 95% CI for RAPI around 95% ~ 97% were observed in our results, implying that RAPI has higher chance and accuracy in capturing true interaction effects within the 95% confidence intervals, compared to matched-pair UPI and 2S-PA-Int. 2S-PA-Int estimated interaction effects with acceptable coverage rates as well, though slightly lower than those estimated by RAPI, implying that 2S-PA-Int is able to capture the true effects with high likelihood. Matched-pair UPI was affected mostly by small sample size and low reliability level, which implied that it was not as robust as RAPI and 2S-PA-Int and not recommended to use under this condition. Our results showed consistency with past research mentioned above; however, Marsh et al. (2004) did not test matched-pair UPI on fully congeneric items and it may imply that matched-pair UPI has less chance of capturing true effects with varied error variances within first-order indicators. 

Sample size and the level of reliability significantly influenced the estimation of non-zero interaction effects. The SB and B values were sensitive to low sample size and high amount of measurement error, reflected by the sample-estimated reliability, such that they generally became smaller with increased sample size and decreased error for all the methods. It means that RAPI, matched-pair UPI, and 2S-PA-Int tend to have better performance in estimating interaction effects with larger sample sizes. Within the same sample size, higher reliability levels of first-order items generally result in more unbiased estimated for all the methods in most cases. The relative SE biases showed similar patterns with sample size and reliability level for the three methods, while RAPI generally exhibited larger biases than matched-pair UPI and 2S-PA-Int especially under small sample size and low reliability level. Thus RAPI is more inclined to generate unstable interaction estimates under such conditions. Overall, although three methods had at least one case of relative SE bias outside the acceptable range, 2S-PA-Int was slightly more stable under most of conditions. In terms of RMSE, it was obviously affected by both sample size and reliability level. For the three methods, as sample size and reliability individually or jointly increase, the RMSE values demonstrated declining trends, meaning that the interaction estimates showed more accuracy and variability. Despite the consistent trends, the 2S-PA-Int method produced estimates with less RMSE particularly under small sample size and low reliability level and thus 2S-PA-Int is more robust to these conditions. Taking all the evaluation criteria into account, 2S-PA-Int shows ample potential to serve as a good alternative to RAPI and matched-UPI for latent interaction estimation.

Revisiting Marsh's criteria of a good model of estimating latent interaction effects, 2S-PA-Int is practically preferable in terms of simple model specification as a single-indicator model and comprehensive usage of information by using factors scores based on all first-order indicators. Specifically, models overloaded with indicators may have difficulties in reaching convergence due to the intricate covariance structures to be estimated, potentially resulting in non-identifiable models (Bollen, 1989). Furthermore, Byrne (2016) highlights that excessive indicators can introduce redundancy, complicating the model unnecessarily and increasing the likelihood of estimation problems. Thus, 2S-PA-Int should be a safer alternative to matched-pair UPI especially with small sample size and low reliability level. Compared to RAPI, 2S-PA-Int is more advantageous in terms of stability and accuracy of interaction estimates. 

## Limitations

A few limitations in the current study are discussed below. First, Hsiao et al. (2018) mentioned that RAPI may be more approachable when researchers do not have the access of original data and have to analyze secondary data since composite scores are usually reported with reliability index (e.g., usually Cronbach's $\alpha$). Since reporting factor scores with standard errors is still not a commonly applied practice, some secondary dataset may not contain computed factors scores and thus 2S-PA-Int is not applicable in this case. Second, currently the congeneric items in this study design are all continuous with normal distributions. Given that categorical data is frequently used in psychology research to capture the qualitative aspects of human behavior, attitudes, and characteristics (Brown, 2015; Kline, 2016), 2S-PA-Int has not been evaluated and should be studied with categorical items in the future. Third, the study designs in the past methodological paper on latent interaction effects were almost simply structured with two latent predictors and one interaction term, which could be insufficient to accommodate more complicated real-world scenarios, such as multiple interaction terms. Besides, multilevel design rencently is increasingly used in educational, counseling, and organizational research (e.g., students nested in classrooms, patients nested in clinics, employees nested in companies). Thus, it is worth exploring the potential of 2S-PA-Int with complicated data types and structures with varied sample sizes and reliability levels. 


