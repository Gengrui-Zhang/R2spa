[{"path":"https://gengrui-zhang.github.io/R2spa/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 R2spa authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/articles/tspa-vignette.html","id":"single-group-single-predictor","dir":"Articles","previous_headings":"","what":"Single group, single predictor1","title":"Two-Stage Path Analysis (2S-PA) Model Examples","text":"call tspa(), data frame factor scores needed latent variables. get data frame, apply get_fs() latent variables specify model parameter respective definitions. Combine factor scores latent variable using cbind() can used tspa() model building. build Two-Stage Path Analysis model, simply call tspa() function model = regressions, data = combined factor score data frame using get_fs(), specify standard error either list data frame. Values standard error can found column named fs_[variable name]_se. example, standard error latent variable ind60 can found column fs_ind60_se fs_dat data frame. view Two-Stage Path Analysis model, use attributes([model name])$tspaModel. Function cat() can help tidy model output. output, values error constraints computed squaring standard errors previous section.","code":"model <- '    # latent variable definitions      ind60 =~ x1 + x2 + x3      dem60 =~ y1 + a*y2 + b*y3 + c*y4    # regressions     dem60 ~ ind60 ' fs_dat_ind60 <- get_fs(data = PoliticalDemocracy,                         model = \"ind60 =~ x1 + x2 + x3\") fs_dat_dem60 <- get_fs(data = PoliticalDemocracy,                         model = \"dem60 =~ y1 + y2 + y3 + y4\") fs_dat <- cbind(fs_dat_ind60, fs_dat_dem60) tspa_fit <- tspa(model = \"dem60 ~ ind60\",                   data = fs_dat,                   se = list(ind60 = 0.1213615, dem60 = 0.6756472)) cat(attributes(tspa_fit)$tspaModel) ## # latent variables (indicated by factor scores) ## ind60 =~ fs_ind60 ## dem60 =~ fs_dem60 ## # constrain the errors ## fs_ind60 ~~ 0.01472861368225 * fs_ind60 ## fs_dem60 ~~ 0.45649913886784 * fs_dem60 ## # latent variances ## ind60 ~~ v1 * ind60 ## dem60 ~~ v2 * dem60 ## # regressions ## dem60 ~ ind60"},{"path":"https://gengrui-zhang.github.io/R2spa/articles/tspa-vignette.html","id":"single-group-multiple-predictors","dir":"Articles","previous_headings":"","what":"Single group, multiple predictors","title":"Two-Stage Path Analysis (2S-PA) Model Examples","text":"call tspa(), data frame factor scores needed latent variables. get data frame, apply get_fs() latent variables specify model parameters respective definitions. Combine factor scores latent variables using cbind() call tspa() model building. build Two-Stage Path Analysis model, simply call tspa() function model = regressions (predictors), data = factor score data frame created combining results get_fs(), specify standard errors either list data frame. Values standard errors can found column named fs_[variable name]_se.2 example, standard error latent variable ind60 can found column fs_ind60_se fs_dat data frame. output model, values error constraints computed squaring standard errors.","code":"model <- '    # latent variable definitions      ind60 =~ x1 + x2 + x3      dem60 =~ y1 + y2 + y3 + y4      dem65 =~ y5 + y6 + y7 + y8    # regressions     dem60 ~ ind60     dem65 ~ ind60 + dem60    # # residual correlations   #   y1 ~~ y5   #   y2 ~~ y4 + y6   #   y3 ~~ y7   #   y4 ~~ y8   #   y6 ~~ y8 ' fs_dat_ind60 <- get_fs(data = PoliticalDemocracy,                         model = \"ind60 =~ x1 + x2 + x3\") fs_dat_dem60 <- get_fs(data = PoliticalDemocracy,                         model = \"dem60 =~ y1 + y2 + y3 + y4\") fs_dat_dem65 <- get_fs(data = PoliticalDemocracy,                         model = \"dem65 =~ y5 + y6 + y7 + y8\") fs_dat <- cbind(fs_dat_ind60, fs_dat_dem60, fs_dat_dem65) tspa_3var_fit <- tspa(model = \"dem60 ~ ind60                           dem65 ~ ind60 + dem60\",                        data = fs_dat,                        se = list(ind60 = 0.1213615, dem60 = 0.6756472,                                  dem65 = 0.5724405)) cat(attributes(tspa_3var_fit)$tspaModel) ## # latent variables (indicated by factor scores) ## ind60 =~ fs_ind60 ## dem60 =~ fs_dem60 ## dem65 =~ fs_dem65 ## # constrain the errors ## fs_ind60 ~~ 0.01472861368225 * fs_ind60 ## fs_dem60 ~~ 0.45649913886784 * fs_dem60 ## fs_dem65 ~~ 0.32768812604025 * fs_dem65 ## # latent variances ## ind60 ~~ v1 * ind60 ## dem60 ~~ v2 * dem60 ## dem65 ~~ v3 * dem65 ## # regressions ## dem60 ~ ind60 ##                           dem65 ~ ind60 + dem60"},{"path":"https://gengrui-zhang.github.io/R2spa/articles/tspa-vignette.html","id":"multigroup-single-predictor","dir":"Articles","previous_headings":"","what":"Multigroup, single predictor","title":"Two-Stage Path Analysis (2S-PA) Model Examples","text":"call tspa(), data frame factor scores needed multigroup variables. get data frame, apply get_fs() multigroup variables specify model parameter respective definitions. Combine factor scores multigroup variables using cbind() can fed tspa() model building. build Two-Stage Path Analysis model, simply call tspa() function model = regression relation. Specify standard error either list data frame. Values standard error can found column named fs_[variable name]_se. example, standard error multigroup variable visual can found column fs_visual_se fs_hs data frame. get standard errors group faster, unique() can called upon standard error column. example, case, unique(fs_hs$fs_visual_se) can called get standard errors multigroup variable visual. Function standardizedsolution() enables user view table standard error, z score, p-value, lower bound confidence interval multigroup regression relation. view Two-Stage Path Analysis model multigroup, use attributes([model name])$tspaModel. Function cat() can help tidy model output. output, values error constraints computed squaring standard errors previous section.","code":"model <- '    # latent variable definitions     visual =~ x1 + x2 + x3     speed =~ x7 + x8 + x9    # regressions     visual ~ speed ' hs_mod <- ' visual =~ x1 + x2 + x3 speed =~ x7 + x8 + x9 '  # get factor scores fs_dat_visual <- get_fs(data = HolzingerSwineford1939,                          model = \"visual =~ x1 + x2 + x3\",                          group = \"school\") fs_dat_speed <- get_fs(data = HolzingerSwineford1939,                         model = \"speed =~ x7 + x8 + x9\",                          group = \"school\") fs_hs <- cbind(fs_dat_visual, fs_dat_speed) # tspa model tspa_fit <- tspa(model = \"visual ~ speed\",                  data = fs_hs,                  se = data.frame(visual = c(0.3391326, 0.311828),                                  speed = c(0.2786875, 0.2740507)),                  group = \"school\"                  # group.equal = \"regressions\"                  ) stdsol <- standardizedsolution(tspa_fit) subset(stdsol, subset = op == \"~\") ##       lhs op   rhs group label est.std    se     z pvalue ci.lower ci.upper ## 7  visual  ~ speed     1         0.277 0.114 2.423  0.015    0.053    0.501 ## 18 visual  ~ speed     2         0.439 0.095 4.627  0.000    0.253    0.625 cat(attributes(tspa_fit)$tspaModel) ## # latent variables (indicated by factor scores) ## visual=~ c(1, 1) * fs_visual ## speed=~ c(1, 1) * fs_speed ## # constrain the errors ## fs_visual~~ c(c(0.11501092038276, 0.097236701584)) * fs_visual ## fs_speed~~ c(c(0.07766672265625, 0.07510378617049)) * fs_speed ## # latent variances ## visual ~~ c(v11, v12) * visual ## speed ~~ c(v21, v22) * speed ## # regressions ## visual ~ speed"},{"path":"https://gengrui-zhang.github.io/R2spa/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mark Hok Chio Lai. Author, maintainer. Yixiao Li. Author. Winnie Wing-Yee Tse. Author. Gengrui Zhang Zhang. Author.","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lai M, Li Y, Tse W, Zhang G (2023). R2spa: R package two-stage path analysis (2S-PA) adjust measurement errors. R package version 0.0.1, https://gengrui-zhang.github.io/R2spa/.","code":"@Manual{,   title = {R2spa: An R package for two-stage path analysis (2S-PA) to adjust for measurement errors},   author = {Mark Hok Chio Lai and Yixiao Li and Winnie Wing-Yee Tse and Gengrui Zhang Zhang},   year = {2023},   note = {R package version 0.0.1},   url = {https://gengrui-zhang.github.io/R2spa/}, }"},{"path":"https://gengrui-zhang.github.io/R2spa/index.html","id":"r2spa","dir":"","previous_headings":"","what":"An R package for two-stage path analysis (2S-PA) to adjust for measurement errors","title":"An R package for two-stage path analysis (2S-PA) to adjust for measurement errors","text":"R2spa free open source R package performs two-stage path analysis (2S-PA). 2S-PA, researchers can perform path analysis first obtaining factor scores adjusting measurement errors using estimates observation-specific reliability standard error factor scores. viable alternative SEM, 2S-PA shown give equally-good estimates SEM relatively simple models large sample sizes, well give accurate parameter estimates, better control Type error rates, substantially less convergence problems complex models small sample sizes.","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"An R package for two-stage path analysis (2S-PA) to adjust for measurement errors","text":"package still developmental stage can installed GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"Gengrui-Zhang/R2spa\")"},{"path":"https://gengrui-zhang.github.io/R2spa/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"An R package for two-stage path analysis (2S-PA) to adjust for measurement errors","text":"","code":"library(lavaan) library(R2spa)  # Joint model model <- '   # latent variable definitions     ind60 =~ x1 + x2 + x3     dem60 =~ y1 + y2 + y3 + y4    # regression     dem60 ~ ind60 ' # 2S-PA # Stage 1: Get factor scores and standard errors for each latent construct fs_dat_ind60 <- get_fs(data = PoliticalDemocracy,                        model = \"ind60 =~ x1 + x2 + x3\") fs_dat_dem60 <- get_fs(data = PoliticalDemocracy,                        model = \"dem60 =~ y1 + y2 + y3 + y4\") fs_dat <- cbind(fs_dat_ind60, fs_dat_dem60)  # get_fs() gives a dataframe with factor scores and standard errors head(fs_dat) #>     fs_ind60 fs_ind60_se   fs_dem60 fs_dem60_se #> 1 -0.5261683   0.1213615 -2.7487224   0.6756472 #> 2  0.1436527   0.1213615 -3.0360803   0.6756472 #> 3  0.7143559   0.1213615  2.6718589   0.6756472 #> 4  1.2399257   0.1213615  2.9936997   0.6756472 #> 5  0.8319080   0.1213615  1.9242932   0.6756472 #> 6  0.2123845   0.1213615  0.9922798   0.6756472 # Stage 2: Perform 2S-PA tspa_fit <- tspa(   model = \"dem60 ~ ind60\",   data = fs_dat,   se = list(ind60 = 0.1213615, dem60 = 0.6756472) ) parameterestimates(tspa_fit) #>        lhs op      rhs label   est    se     z pvalue ci.lower ci.upper #> 1    ind60 =~ fs_ind60       1.000 0.000    NA     NA    1.000    1.000 #> 2    dem60 =~ fs_dem60       1.000 0.000    NA     NA    1.000    1.000 #> 3 fs_ind60 ~~ fs_ind60       0.015 0.000    NA     NA    0.015    0.015 #> 4 fs_dem60 ~~ fs_dem60       0.456 0.000    NA     NA    0.456    0.456 #> 5    ind60 ~~    ind60    v1 0.416 0.070 5.914      0    0.278    0.553 #> 6    dem60 ~~    dem60    v2 2.842 0.543 5.235      0    1.778    3.906 #> 7    dem60  ~    ind60       1.329 0.332 4.000      0    0.678    1.981"},{"path":"https://gengrui-zhang.github.io/R2spa/reference/compute_fscore.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute factor scores — compute_fscore","title":"Compute factor scores — compute_fscore","text":"Compute factor scores","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/reference/compute_fscore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute factor scores — compute_fscore","text":"","code":"compute_fscore(   y,   lambda,   theta,   psi,   nu = NULL,   alpha = NULL,   method = c(\"regression\", \"Bartlett\"),   acov = FALSE,   fs_matrices = FALSE )"},{"path":"https://gengrui-zhang.github.io/R2spa/reference/compute_fscore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute factor scores — compute_fscore","text":"y N x p matrix row response vector. one observation, matrix one row. lambda p x q matrix factor loadings. theta p x p matrix unique variance-covariances. psi q x q matrix latent factor variance-covariances. nu vector length p measurement intercepts. alpha vector length q latent means. method character string indicating method computing factor scores. Currently, \"regression\" supported. acov Logical indicating whether asymptotic covariance matrix factor scores returned attribute. fs_matrices Logical indicating whether covariances error portion factor scores (av_efs), factor score loading matrix (\\(\\); fsA) intercept vector (\\(b\\); fsb) returned. loading intercept matrices implied loadings intercepts model using factor scores indicators latent variables. TRUE, matrices added attributes.","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/reference/compute_fscore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute factor scores — compute_fscore","text":"N x p matrix factor scores.","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/reference/compute_fscore.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute factor scores — compute_fscore","text":"","code":"library(lavaan) #> This is lavaan 0.6-13 #> lavaan is FREE software! Please report any bugs. fit <- cfa(\" ind60 =~ x1 + x2 + x3              dem60 =~ y1 + y2 + y3 + y4 \",            data = PoliticalDemocracy) fs_lavaan <- lavPredict(fit, method = \"Bartlett\") # Using R2spa::compute_fscore() est <- lavInspect(fit, what = \"est\") fs_hand <- compute_fscore(lavInspect(fit, what = \"data\"),                           lambda = est$lambda,                           theta = est$theta,                           psi = est$psi,                           method = \"Bartlett\") fs_hand - fs_lavaan  # same scores #>       ind60 dem60 #>  [1,]     0     0 #>  [2,]     0     0 #>  [3,]     0     0 #>  [4,]     0     0 #>  [5,]     0     0 #>  [6,]     0     0 #>  [7,]     0     0 #>  [8,]     0     0 #>  [9,]     0     0 #> [10,]     0     0 #> [11,]     0     0 #> [12,]     0     0 #> [13,]     0     0 #> [14,]     0     0 #> [15,]     0     0 #> [16,]     0     0 #> [17,]     0     0 #> [18,]     0     0 #> [19,]     0     0 #> [20,]     0     0 #> [21,]     0     0 #> [22,]     0     0 #> [23,]     0     0 #> [24,]     0     0 #> [25,]     0     0 #> [26,]     0     0 #> [27,]     0     0 #> [28,]     0     0 #> [29,]     0     0 #> [30,]     0     0 #> [31,]     0     0 #> [32,]     0     0 #> [33,]     0     0 #> [34,]     0     0 #> [35,]     0     0 #> [36,]     0     0 #> [37,]     0     0 #> [38,]     0     0 #> [39,]     0     0 #> [40,]     0     0 #> [41,]     0     0 #> [42,]     0     0 #> [43,]     0     0 #> [44,]     0     0 #> [45,]     0     0 #> [46,]     0     0 #> [47,]     0     0 #> [48,]     0     0 #> [49,]     0     0 #> [50,]     0     0 #> [51,]     0     0 #> [52,]     0     0 #> [53,]     0     0 #> [54,]     0     0 #> [55,]     0     0 #> [56,]     0     0 #> [57,]     0     0 #> [58,]     0     0 #> [59,]     0     0 #> [60,]     0     0 #> [61,]     0     0 #> [62,]     0     0 #> [63,]     0     0 #> [64,]     0     0 #> [65,]     0     0 #> [66,]     0     0 #> [67,]     0     0 #> [68,]     0     0 #> [69,]     0     0 #> [70,]     0     0 #> [71,]     0     0 #> [72,]     0     0 #> [73,]     0     0 #> [74,]     0     0 #> [75,]     0     0"},{"path":"https://gengrui-zhang.github.io/R2spa/reference/get_fs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Factor Scores and the Corresponding Standard Error of Measurement — get_fs","title":"Get Factor Scores and the Corresponding Standard Error of Measurement — get_fs","text":"Get Factor Scores Corresponding Standard Error Measurement","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/reference/get_fs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Factor Scores and the Corresponding Standard Error of Measurement — get_fs","text":"","code":"get_fs(   data,   model = NULL,   group = NULL,   method = c(\"regression\", \"Bartlett\"),   ... )"},{"path":"https://gengrui-zhang.github.io/R2spa/reference/get_fs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Factor Scores and the Corresponding Standard Error of Measurement — get_fs","text":"data data frame containing indicators. model optional string specifying measurement model lavaan syntax. See model.syntax information. group Character. Name grouping variable multiple group analysis, passed cfa. method Character. Method computing factor scores (options \"regression\" \"Bartlett\"). Currently, default \"regression\" consistent lavPredict, Bartlett scores desirable properties may preferred 2S-PA. ... additional arguments passed cfa. See lavOptions complete list.","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/reference/get_fs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Factor Scores and the Corresponding Standard Error of Measurement — get_fs","text":"data frame containing factor scores (prefix \"fs_\") standard errors (suffix \"_se\").","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/reference/get_fs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Factor Scores and the Corresponding Standard Error of Measurement — get_fs","text":"","code":"library(lavaan) get_fs(PoliticalDemocracy[c(\"x1\", \"x2\", \"x3\")]) #>          fs_f1  fs_f1_se #> 1  -0.52616832 0.1213615 #> 2   0.14365274 0.1213615 #> 3   0.71435592 0.1213615 #> 4   1.23992565 0.1213615 #> 5   0.83190803 0.1213615 #> 6   0.21238453 0.1213615 #> 7   0.11880855 0.1213615 #> 8   0.11322703 0.1213615 #> 9   0.25617279 0.1213615 #> 10  0.37112496 0.1213615 #> 11  0.67281395 0.1213615 #> 12  0.56885577 0.1213615 #> 13  1.31369791 0.1213615 #> 14  0.22042629 0.1213615 #> 15  0.57849228 0.1213615 #> 16  0.37805983 0.1213615 #> 17  0.05734046 0.1213615 #> 18 -0.01609202 0.1213615 #> 19  0.88923616 0.1213615 #> 20  1.11445897 0.1213615 #> 21  0.94657339 0.1213615 #> 22  0.90122770 0.1213615 #> 23  0.58409450 0.1213615 #> 24  0.64089192 0.1213615 #> 25  0.91021968 0.1213615 #> 26 -0.89660969 0.1213615 #> 27 -0.13195991 0.1213615 #> 28 -0.52968769 0.1213615 #> 29 -0.81799629 0.1213615 #> 30 -1.27199371 0.1213615 #> 31 -0.32096024 0.1213615 #> 32 -1.16780103 0.1213615 #> 33 -0.12295473 0.1213615 #> 34 -0.04285945 0.1213615 #> 35 -0.34323505 0.1213615 #> 36 -0.60541633 0.1213615 #> 37  0.17688718 0.1213615 #> 38 -0.55066055 0.1213615 #> 39 -1.05988219 0.1213615 #> 40 -0.04138802 0.1213615 #> 41 -0.12611837 0.1213615 #> 42 -0.60322892 0.1213615 #> 43 -0.11057176 0.1213615 #> 44 -1.06423085 0.1213615 #> 45 -1.08354999 0.1213615 #> 46 -0.84009484 0.1213615 #> 47 -1.14678213 0.1213615 #> 48 -0.57578976 0.1213615 #> 49  0.07186692 0.1213615 #> 50  0.14682421 0.1213615 #> 51  0.35871830 0.1213615 #> 52 -0.43403195 0.1213615 #> 53  0.44603111 0.1213615 #> 54  0.26352000 0.1213615 #> 55  0.55051165 0.1213615 #> 56  0.23453122 0.1213615 #> 57  0.27968138 0.1213615 #> 58  0.70960640 0.1213615 #> 59  0.25227978 0.1213615 #> 60  1.18849297 0.1213615 #> 61  0.21104946 0.1213615 #> 62 -1.16516281 0.1213615 #> 63 -0.85560065 0.1213615 #> 64  0.13398476 0.1213615 #> 65 -0.07912189 0.1213615 #> 66 -0.27146711 0.1213615 #> 67 -0.04417217 0.1213615 #> 68 -1.33425662 0.1213615 #> 69 -0.38720750 0.1213615 #> 70 -0.55355511 0.1213615 #> 71 -0.72242623 0.1213615 #> 72  0.30607449 0.1213615 #> 73  0.77707950 0.1213615 #> 74  0.06847481 0.1213615 #> 75 -0.11052927 0.1213615  # Multiple factors get_fs(PoliticalDemocracy[c(\"x1\", \"x2\", \"x3\", \"y1\", \"y2\", \"y3\", \"y4\")],        model = \" ind60 =~ x1 + x2 + x3                  dem60 =~ y1 + y2 + y3 + y4 \") #>       fs_ind60    fs_dem60 fs_ind60_se fs_dem60_se #> 1  -0.54258816 -2.74640573   0.1245694   0.6307323 #> 2   0.12647664 -2.85646114   0.1245694   0.6307323 #> 3   0.73408891  2.74401728   0.1245694   0.6307323 #> 4   1.25253604  3.10856431   0.1245694   0.6307323 #> 5   0.83355267  1.92455641   0.1245694   0.6307323 #> 6   0.22426801  1.02292332   0.1245694   0.6307323 #> 7   0.12517739  1.00406461   0.1245694   0.6307323 #> 8   0.11783867 -0.37216403   0.1245694   0.6307323 #> 9   0.25175134 -1.24897911   0.1245694   0.6307323 #> 10  0.39938631  2.85267059   0.1245694   0.6307323 #> 11  0.67497777  1.41959595   0.1245694   0.6307323 #> 12  0.56462020  1.08769844   0.1245694   0.6307323 #> 13  1.31236592  1.54090232   0.1245694   0.6307323 #> 14  0.23246021  1.77370863   0.1245694   0.6307323 #> 15  0.58638481  2.45676871   0.1245694   0.6307323 #> 16  0.38404785  2.35887573   0.1245694   0.6307323 #> 17  0.05076465  0.04034088   0.1245694   0.6307323 #> 18 -0.01747337 -1.86718064   0.1245694   0.6307323 #> 19  0.90920762  3.61477756   0.1245694   0.6307323 #> 20  1.12553557  0.88355273   0.1245694   0.6307323 #> 21  0.97202590  3.62673300   0.1245694   0.6307323 #> 22  0.87820036 -3.02428925   0.1245694   0.6307323 #> 23  0.57540754 -1.51695438   0.1245694   0.6307323 #> 24  0.66221224  2.76341635   0.1245694   0.6307323 #> 25  0.92358281  2.00507336   0.1245694   0.6307323 #> 26 -0.89353051 -0.92008050   0.1245694   0.6307323 #> 27 -0.13984744 -1.19025576   0.1245694   0.6307323 #> 28 -0.53828496 -1.01247764   0.1245694   0.6307323 #> 29 -0.80834865  0.10456709   0.1245694   0.6307323 #> 30 -1.25324343 -0.71847055   0.1245694   0.6307323 #> 31 -0.33373641 -1.61401581   0.1245694   0.6307323 #> 32 -1.17441075 -3.27250363   0.1245694   0.6307323 #> 33 -0.12409974 -1.17530231   0.1245694   0.6307323 #> 34 -0.04239173 -0.53796274   0.1245694   0.6307323 #> 35 -0.34010528  0.74552889   0.1245694   0.6307323 #> 36 -0.58953870  1.61018662   0.1245694   0.6307323 #> 37  0.17453657 -0.28144814   0.1245694   0.6307323 #> 38 -0.54457243  0.37694690   0.1245694   0.6307323 #> 39 -1.05196602 -0.62919501   0.1245694   0.6307323 #> 40 -0.05504697 -0.03346842   0.1245694   0.6307323 #> 41 -0.12364358 -0.38394102   0.1245694   0.6307323 #> 42 -0.59058710  1.35347275   0.1245694   0.6307323 #> 43 -0.11968796  0.89227782   0.1245694   0.6307323 #> 44 -1.07176064 -2.08481096   0.1245694   0.6307323 #> 45 -1.09139097 -2.07944291   0.1245694   0.6307323 #> 46 -0.83287255  1.59590721   0.1245694   0.6307323 #> 47 -1.14519896 -1.53352201   0.1245694   0.6307323 #> 48 -0.56115378  2.08138051   0.1245694   0.6307323 #> 49  0.06493340 -1.04044137   0.1245694   0.6307323 #> 50  0.15671638  1.72618633   0.1245694   0.6307323 #> 51  0.34626130 -1.24967043   0.1245694   0.6307323 #> 52 -0.45158373 -2.31742576   0.1245694   0.6307323 #> 53  0.43233465 -1.07533341   0.1245694   0.6307323 #> 54  0.25779725 -0.02904676   0.1245694   0.6307323 #> 55  0.51730650 -2.78207923   0.1245694   0.6307323 #> 56  0.20104991 -2.49001474   0.1245694   0.6307323 #> 57  0.25318620 -2.52145147   0.1245694   0.6307323 #> 58  0.72354623  1.86717109   0.1245694   0.6307323 #> 59  0.24619740 -0.93321102   0.1245694   0.6307323 #> 60  1.21681210  3.19853937   0.1245694   0.6307323 #> 61  0.18167599 -3.15685030   0.1245694   0.6307323 #> 62 -1.16605067 -3.41334680   0.1245694   0.6307323 #> 63 -0.86491026 -3.11864398   0.1245694   0.6307323 #> 64  0.10990059 -0.47238885   0.1245694   0.6307323 #> 65 -0.07376176  2.95292007   0.1245694   0.6307323 #> 66 -0.28782931 -1.96509718   0.1245694   0.6307323 #> 67 -0.02508160  2.96218478   0.1245694   0.6307323 #> 68 -1.31843215 -1.59567027   0.1245694   0.6307323 #> 69 -0.40462357 -1.79146161   0.1245694   0.6307323 #> 70 -0.55568363 -1.01578892   0.1245694   0.6307323 #> 71 -0.71308015  0.08818212   0.1245694   0.6307323 #> 72  0.31014319  1.70765911   0.1245694   0.6307323 #> 73  0.79092897  1.86102556   0.1245694   0.6307323 #> 74  0.08770237  3.12885767   0.1245694   0.6307323 #> 75 -0.14138149 -2.41398025   0.1245694   0.6307323  # Multiple-group hs_model <- ' visual  =~ x1 + x2 + x3 ' fit <- cfa(hs_model,            data = HolzingerSwineford1939,            group = \"school\") get_fs(HolzingerSwineford1939, hs_model, group = \"school\") #>        fs_visual fs_visual_se      school #> 1   -0.821165191    0.3391326     Pasteur #> 2   -0.124009418    0.3391326     Pasteur #> 3   -0.370072089    0.3391326     Pasteur #> 4    0.440928618    0.3391326     Pasteur #> 5   -0.691389016    0.3391326     Pasteur #> 6   -0.110032619    0.3391326     Pasteur #> 7   -0.904127845    0.3391326     Pasteur #> 8   -0.031747573    0.3391326     Pasteur #> 9   -0.439478981    0.3391326     Pasteur #> 10  -0.938939050    0.3391326     Pasteur #> 11  -0.436821880    0.3391326     Pasteur #> 12   0.305033497    0.3391326     Pasteur #> 13   0.522076263    0.3391326     Pasteur #> 14  -0.090367931    0.3391326     Pasteur #> 15   0.526276771    0.3391326     Pasteur #> 16  -0.226580678    0.3391326     Pasteur #> 17  -0.582016192    0.3391326     Pasteur #> 18   0.017040431    0.3391326     Pasteur #> 19   0.563052459    0.3391326     Pasteur #> 20   0.746621910    0.3391326     Pasteur #> 21   0.234672405    0.3391326     Pasteur #> 22   1.157487518    0.3391326     Pasteur #> 23  -0.162272449    0.3391326     Pasteur #> 24  -0.556027059    0.3391326     Pasteur #> 25  -0.321443540    0.3391326     Pasteur #> 26   0.153141050    0.3391326     Pasteur #> 27   0.696234416    0.3391326     Pasteur #> 28  -0.020961039    0.3391326     Pasteur #> 29   0.532601236    0.3391326     Pasteur #> 30  -0.727687585    0.3391326     Pasteur #> 31  -0.676719580    0.3391326     Pasteur #> 32  -1.120216393    0.3391326     Pasteur #> 33  -0.313631732    0.3391326     Pasteur #> 34  -0.187091845    0.3391326     Pasteur #> 35  -0.887709484    0.3391326     Pasteur #> 36  -0.760795908    0.3391326     Pasteur #> 37   0.556943532    0.3391326     Pasteur #> 38  -0.458666570    0.3391326     Pasteur #> 39   0.514741536    0.3391326     Pasteur #> 40   0.373009089    0.3391326     Pasteur #> 41  -0.528550562    0.3391326     Pasteur #> 42  -0.865864795    0.3391326     Pasteur #> 43  -1.182344640    0.3391326     Pasteur #> 44  -0.435334517    0.3391326     Pasteur #> 45   0.306520860    0.3391326     Pasteur #> 46   0.821604565    0.3391326     Pasteur #> 47   1.213927875    0.3391326     Pasteur #> 48  -0.851887996    0.3391326     Pasteur #> 49  -0.085053749    0.3391326     Pasteur #> 50  -0.508885873    0.3391326     Pasteur #> 51   0.502467638    0.3391326     Pasteur #> 52   0.284732253    0.3391326     Pasteur #> 53   0.202677755    0.3391326     Pasteur #> 54  -0.335953502    0.3391326     Pasteur #> 55   0.556410369    0.3391326     Pasteur #> 56  -0.058746970    0.3391326     Pasteur #> 57  -0.066932487    0.3391326     Pasteur #> 58   0.554230368    0.3391326     Pasteur #> 59  -0.321761185    0.3391326     Pasteur #> 60  -0.421834819    0.3391326     Pasteur #> 61   0.345476529    0.3391326     Pasteur #> 62   0.194809883    0.3391326     Pasteur #> 63  -0.207870208    0.3391326     Pasteur #> 64  -0.441658981    0.3391326     Pasteur #> 65   0.102070958    0.3391326     Pasteur #> 66   0.311198487    0.3391326     Pasteur #> 67   0.676364229    0.3391326     Pasteur #> 68   0.297858262    0.3391326     Pasteur #> 69  -1.055487128    0.3391326     Pasteur #> 70  -0.737997019    0.3391326     Pasteur #> 71  -1.576099236    0.3391326     Pasteur #> 72   0.534360181    0.3391326     Pasteur #> 73  -0.105888156    0.3391326     Pasteur #> 74   0.266237302    0.3391326     Pasteur #> 75  -0.352427927    0.3391326     Pasteur #> 76  -0.334783784    0.3391326     Pasteur #> 77   0.133588508    0.3391326     Pasteur #> 78  -1.035662965    0.3391326     Pasteur #> 79   0.762507108    0.3391326     Pasteur #> 80  -0.260699265    0.3391326     Pasteur #> 81  -0.329095893    0.3391326     Pasteur #> 82   0.752413211    0.3391326     Pasteur #> 83   0.149268188    0.3391326     Pasteur #> 84  -0.208880471    0.3391326     Pasteur #> 85  -1.078285998    0.3391326     Pasteur #> 86   0.306043760    0.3391326     Pasteur #> 87   0.349677056    0.3391326     Pasteur #> 88   0.165686549    0.3391326     Pasteur #> 89   0.077307606    0.3391326     Pasteur #> 90  -0.077401396    0.3391326     Pasteur #> 91  -0.081863485    0.3391326     Pasteur #> 92   0.106748566    0.3391326     Pasteur #> 93  -0.211593616    0.3391326     Pasteur #> 94  -0.926665153    0.3391326     Pasteur #> 95  -0.739484382    0.3391326     Pasteur #> 96   0.570387167    0.3391326     Pasteur #> 97  -0.913642554    0.3391326     Pasteur #> 98   0.547484887    0.3391326     Pasteur #> 99  -0.602850599    0.3391326     Pasteur #> 100  0.225794270    0.3391326     Pasteur #> 101  0.620447015    0.3391326     Pasteur #> 102  0.158885005    0.3391326     Pasteur #> 103 -0.127938344    0.3391326     Pasteur #> 104 -0.420347455    0.3391326     Pasteur #> 105  1.327978307    0.3391326     Pasteur #> 106  0.181843348    0.3391326     Pasteur #> 107 -0.148932224    0.3391326     Pasteur #> 108  0.612373626    0.3391326     Pasteur #> 109 -0.066558798    0.3391326     Pasteur #> 110 -0.420880619    0.3391326     Pasteur #> 111  1.127036295    0.3391326     Pasteur #> 112  0.237591068    0.3391326     Pasteur #> 113  0.853758689    0.3391326     Pasteur #> 114 -0.143618023    0.3391326     Pasteur #> 115  0.475206679    0.3391326     Pasteur #> 116 -0.670554590    0.3391326     Pasteur #> 117  0.022672257    0.3391326     Pasteur #> 118  0.302002707    0.3391326     Pasteur #> 119  0.151392125    0.3391326     Pasteur #> 120 -0.475300449    0.3391326     Pasteur #> 121 -0.346740056    0.3391326     Pasteur #> 122 -0.078888759    0.3391326     Pasteur #> 123  1.197237913    0.3391326     Pasteur #> 124  0.539243306    0.3391326     Pasteur #> 125  0.867258388    0.3391326     Pasteur #> 126  0.592287901    0.3391326     Pasteur #> 127 -0.500540901    0.3391326     Pasteur #> 128 -0.361193954    0.3391326     Pasteur #> 129  0.626883588    0.3391326     Pasteur #> 130 -0.437514518    0.3391326     Pasteur #> 131  0.695972854    0.3391326     Pasteur #> 132  0.424715775    0.3391326     Pasteur #> 133 -0.203725744    0.3391326     Pasteur #> 134 -0.441499507    0.3391326     Pasteur #> 135  0.735619838    0.3391326     Pasteur #> 136  0.783874697    0.3391326     Pasteur #> 137  0.565709540    0.3391326     Pasteur #> 138  0.258425494    0.3391326     Pasteur #> 139  0.861093397    0.3391326     Pasteur #> 140 -0.059757233    0.3391326     Pasteur #> 141 -0.920340689    0.3391326     Pasteur #> 142  0.845629236    0.3391326     Pasteur #> 143  1.227427574    0.3391326     Pasteur #> 144  1.054223601    0.3391326     Pasteur #> 145 -1.246596805    0.3391326     Pasteur #> 146 -0.473120468    0.3391326     Pasteur #> 147 -0.560171503    0.3391326     Pasteur #> 148 -0.365394462    0.3391326     Pasteur #> 149  0.084744422    0.3391326     Pasteur #> 150  0.910676146    0.3391326     Pasteur #> 151  1.094189533    0.3391326     Pasteur #> 152 -0.013149231    0.3391326     Pasteur #> 153 -0.166472976    0.3391326     Pasteur #> 154  0.008695459    0.3391326     Pasteur #> 155 -0.094989494    0.3391326     Pasteur #> 156 -0.457123143    0.3391326     Pasteur #> 157 -0.915287109    0.3118280 Grant-White #> 158  0.035963597    0.3118280 Grant-White #> 159  0.355636604    0.3118280 Grant-White #> 160 -0.387353871    0.3118280 Grant-White #> 161 -0.622393942    0.3118280 Grant-White #> 162  0.195944561    0.3118280 Grant-White #> 163  1.353023831    0.3118280 Grant-White #> 164 -0.341506254    0.3118280 Grant-White #> 165 -0.199493575    0.3118280 Grant-White #> 166 -0.689869149    0.3118280 Grant-White #> 167 -0.463929554    0.3118280 Grant-White #> 168 -0.423001505    0.3118280 Grant-White #> 169  0.279743296    0.3118280 Grant-White #> 170 -0.916908219    0.3118280 Grant-White #> 171  0.589344501    0.3118280 Grant-White #> 172  0.191474701    0.3118280 Grant-White #> 173  0.935275715    0.3118280 Grant-White #> 174  0.393715904    0.3118280 Grant-White #> 175  0.086569994    0.3118280 Grant-White #> 176  0.555606898    0.3118280 Grant-White #> 177 -0.558217193    0.3118280 Grant-White #> 178  0.766715894    0.3118280 Grant-White #> 179  0.115548801    0.3118280 Grant-White #> 180  0.901249191    0.3118280 Grant-White #> 181  0.174316971    0.3118280 Grant-White #> 182 -0.078980322    0.3118280 Grant-White #> 183 -0.581882977    0.3118280 Grant-White #> 184 -0.661179262    0.3118280 Grant-White #> 185 -0.245341176    0.3118280 Grant-White #> 186 -0.195801662    0.3118280 Grant-White #> 187 -0.281221524    0.3118280 Grant-White #> 188 -0.293909378    0.3118280 Grant-White #> 189 -0.604192958    0.3118280 Grant-White #> 190 -0.738437335    0.3118280 Grant-White #> 191 -0.304109345    0.3118280 Grant-White #> 192  0.104931733    0.3118280 Grant-White #> 193 -0.025781487    0.3118280 Grant-White #> 194 -0.897318824    0.3118280 Grant-White #> 195 -0.892560027    0.3118280 Grant-White #> 196 -0.078402465    0.3118280 Grant-White #> 197 -0.379063934    0.3118280 Grant-White #> 198 -0.324926380    0.3118280 Grant-White #> 199 -0.684299797    0.3118280 Grant-White #> 200 -0.304109345    0.3118280 Grant-White #> 201  0.622793169    0.3118280 Grant-White #> 202 -0.152835419    0.3118280 Grant-White #> 203 -0.421902013    0.3118280 Grant-White #> 204 -0.060883872    0.3118280 Grant-White #> 205 -0.303298790    0.3118280 Grant-White #> 206  0.425021826    0.3118280 Grant-White #> 207  0.131478875    0.3118280 Grant-White #> 208 -0.914998172    0.3118280 Grant-White #> 209  0.324226132    0.3118280 Grant-White #> 210 -0.086170767    0.3118280 Grant-White #> 211  0.428424818    0.3118280 Grant-White #> 212  0.188465179    0.3118280 Grant-White #> 213 -0.306958111    0.3118280 Grant-White #> 214  0.581736955    0.3118280 Grant-White #> 215 -0.743485051    0.3118280 Grant-White #> 216  0.263580524    0.3118280 Grant-White #> 217  0.178786831    0.3118280 Grant-White #> 218 -0.064832113    0.3118280 Grant-White #> 219  0.499976414    0.3118280 Grant-White #> 220 -0.092839593    0.3118280 Grant-White #> 221 -0.263702931    0.3118280 Grant-White #> 222 -0.983966325    0.3118280 Grant-White #> 223  1.434912536    0.3118280 Grant-White #> 224 -1.037582228    0.3118280 Grant-White #> 225 -0.047569849    0.3118280 Grant-White #> 226  1.084767775    0.3118280 Grant-White #> 227  0.092011181    0.3118280 Grant-White #> 228 -0.562687052    0.3118280 Grant-White #> 229 -0.304919900    0.3118280 Grant-White #> 230  1.038920175    0.3118280 Grant-White #> 231 -0.789854287    0.3118280 Grant-White #> 232 -0.602282928    0.3118280 Grant-White #> 233 -0.894630830    0.3118280 Grant-White #> 234  0.532614527    0.3118280 Grant-White #> 235 -0.548955945    0.3118280 Grant-White #> 236 -0.221514635    0.3118280 Grant-White #> 237 -0.095849115    0.3118280 Grant-White #> 238 -0.122235502    0.3118280 Grant-White #> 239  0.892276864    0.3118280 Grant-White #> 240  0.328439663    0.3118280 Grant-White #> 241  1.217391042    0.3118280 Grant-White #> 242  0.574513902    0.3118280 Grant-White #> 243  0.160168762    0.3118280 Grant-White #> 244  0.654909662    0.3118280 Grant-White #> 245 -0.509777155    0.3118280 Grant-White #> 246  1.201493560    0.3118280 Grant-White #> 247  0.584874625    0.3118280 Grant-White #> 248  0.075142371    0.3118280 Grant-White #> 249  0.550976266    0.3118280 Grant-White #> 250 -0.886308302    0.3118280 Grant-White #> 251  0.552075757    0.3118280 Grant-White #> 252  1.415972940    0.3118280 Grant-White #> 253  0.298650301    0.3118280 Grant-White #> 254 -0.143028906    0.3118280 Grant-White #> 255  0.245195154    0.3118280 Grant-White #> 256  0.247072593    0.3118280 Grant-White #> 257  0.817322291    0.3118280 Grant-White #> 258  0.651771976    0.3118280 Grant-White #> 259  1.338875623    0.3118280 Grant-White #> 260 -1.160005528    0.3118280 Grant-White #> 261  0.163306449    0.3118280 Grant-White #> 262 -0.387353871    0.3118280 Grant-White #> 263 -0.517128372    0.3118280 Grant-White #> 264  0.065103160    0.3118280 Grant-White #> 265 -0.115438510    0.3118280 Grant-White #> 266  0.094049376    0.3118280 Grant-White #> 267  0.396725409    0.3118280 Grant-White #> 268  0.672356312    0.3118280 Grant-White #> 269  1.165974090    0.3118280 Grant-White #> 270 -0.483518949    0.3118280 Grant-White #> 271  0.035024877    0.3118280 Grant-White #> 272  0.741974248    0.3118280 Grant-White #> 273 -0.170386603    0.3118280 Grant-White #> 274 -0.205873481    0.3118280 Grant-White #> 275  0.714777307    0.3118280 Grant-White #> 276 -0.620772831    0.3118280 Grant-White #> 277 -0.313626938    0.3118280 Grant-White #> 278 -0.157466035    0.3118280 Grant-White #> 279  0.118269386    0.3118280 Grant-White #> 280  0.101111673    0.3118280 Grant-White #> 281 -0.625403463    0.3118280 Grant-White #> 282  0.486638761    0.3118280 Grant-White #> 283 -0.178676540    0.3118280 Grant-White #> 284  0.274013189    0.3118280 Grant-White #> 285 -0.316347523    0.3118280 Grant-White #> 286 -0.026752814    0.3118280 Grant-White #> 287  0.245323318    0.3118280 Grant-White #> 288 -0.356336853    0.3118280 Grant-White #> 289 -0.581594057    0.3118280 Grant-White #> 290  0.263002667    0.3118280 Grant-White #> 291 -0.864680712    0.3118280 Grant-White #> 292 -0.377964443    0.3118280 Grant-White #> 293 -0.112717909    0.3118280 Grant-White #> 294  0.114449326    0.3118280 Grant-White #> 295  0.001287274    0.3118280 Grant-White #> 296  0.597634438    0.3118280 Grant-White #> 297 -0.252531637    0.3118280 Grant-White #> 298 -0.472901881    0.3118280 Grant-White #> 299 -0.187255397    0.3118280 Grant-White #> 300 -0.542415283    0.3118280 Grant-White #> 301  0.358774274    0.3118280 Grant-White # Or without the model get_fs(HolzingerSwineford1939[c(\"school\", \"x4\", \"x5\", \"x6\")],        group = \"school\") #>             fs_f1  fs_f1_se      school #> 1    0.3074500370 0.2999315     Pasteur #> 2   -0.7746062892 0.2999315     Pasteur #> 3   -1.5843019574 0.2999315     Pasteur #> 4    0.2739579120 0.2999315     Pasteur #> 5    0.1440153923 0.2999315     Pasteur #> 6   -1.0440895948 0.2999315     Pasteur #> 7    1.0507357396 0.2999315     Pasteur #> 8    0.1041882698 0.2999315     Pasteur #> 9    0.7750146375 0.2999315     Pasteur #> 10   0.4822117444 0.2999315     Pasteur #> 11  -0.4511886490 0.2999315     Pasteur #> 12   0.3522691973 0.2999315     Pasteur #> 13   0.0657041070 0.2999315     Pasteur #> 14   0.3259750264 0.2999315     Pasteur #> 15   1.3008341323 0.2999315     Pasteur #> 16  -0.2804588573 0.2999315     Pasteur #> 17  -0.3604017581 0.2999315     Pasteur #> 18  -0.7502293722 0.2999315     Pasteur #> 19   1.2600468631 0.2999315     Pasteur #> 20   0.2874908636 0.2999315     Pasteur #> 21  -1.1394826729 0.2999315     Pasteur #> 22  -0.3791151940 0.2999315     Pasteur #> 23   1.0444979094 0.2999315     Pasteur #> 24  -0.6248930150 0.2999315     Pasteur #> 25  -0.3689426673 0.2999315     Pasteur #> 26  -0.5663524842 0.2999315     Pasteur #> 27  -0.9568515617 0.2999315     Pasteur #> 28  -0.8137619455 0.2999315     Pasteur #> 29  -0.5028199109 0.2999315     Pasteur #> 30  -0.3054100713 0.2999315     Pasteur #> 31  -0.3728773637 0.2999315     Pasteur #> 32  -0.8529175744 0.2999315     Pasteur #> 33   0.4101382620 0.2999315     Pasteur #> 34   0.1848026386 0.2999315     Pasteur #> 35  -0.9680814159 0.2999315     Pasteur #> 36  -0.1436070439 0.2999315     Pasteur #> 37  -0.0126071782 0.2999315     Pasteur #> 38  -0.3531066368 0.2999315     Pasteur #> 39   1.0665717701 0.2999315     Pasteur #> 40   0.7993915544 0.2999315     Pasteur #> 41   0.1110975387 0.2999315     Pasteur #> 42  -0.2735495637 0.2999315     Pasteur #> 43  -0.7167372327 0.2999315     Pasteur #> 44  -0.6594424814 0.2999315     Pasteur #> 45   0.9507364688 0.2999315     Pasteur #> 46  -0.0478281107 0.2999315     Pasteur #> 47  -1.7573348450 0.2999315     Pasteur #> 48  -0.4620326417 0.2999315     Pasteur #> 49  -1.0305566597 0.2999315     Pasteur #> 50   0.7618675383 0.2999315     Pasteur #> 51  -1.3414986833 0.2999315     Pasteur #> 52  -0.0761397743 0.2999315     Pasteur #> 53  -1.8231705136 0.2999315     Pasteur #> 54   0.0094666323 0.2999315     Pasteur #> 55   0.0436302463 0.2999315     Pasteur #> 56  -0.0001315726 0.2999315     Pasteur #> 57  -0.6571393750 0.2999315     Pasteur #> 58   0.6121542642 0.2999315     Pasteur #> 59  -1.0957208458 0.2999315     Pasteur #> 60  -0.9289257761 0.2999315     Pasteur #> 61   0.9553426588 0.2999315     Pasteur #> 62   0.3647448029 0.2999315     Pasteur #> 63  -1.1003270330 0.2999315     Pasteur #> 64   0.4259742697 0.2999315     Pasteur #> 65   0.1689666035 0.2999315     Pasteur #> 66   0.6586050419 0.2999315     Pasteur #> 67  -0.2952375720 0.2999315     Pasteur #> 68  -0.4745082474 0.2999315     Pasteur #> 69  -0.5613604418 0.2999315     Pasteur #> 70   0.5632119383 0.2999315     Pasteur #> 71  -0.7769093955 0.2999315     Pasteur #> 72  -1.1434174113 0.2999315     Pasteur #> 73  -0.7808440920 0.2999315     Pasteur #> 74   0.9270309952 0.2999315     Pasteur #> 75  -0.5426470306 0.2999315     Pasteur #> 76  -1.1065648385 0.2999315     Pasteur #> 77   0.6233841094 0.2999315     Pasteur #> 78  -1.7010974136 0.2999315     Pasteur #> 79  -0.0013773330 0.2999315     Pasteur #> 80  -1.2772946275 0.2999315     Pasteur #> 81  -1.0344913561 0.2999315     Pasteur #> 82   0.4345151789 0.2999315     Pasteur #> 83  -1.5280645151 0.2999315     Pasteur #> 84  -0.6101143231 0.2999315     Pasteur #> 85  -1.5122284832 0.2999315     Pasteur #> 86   1.2011204798 0.2999315     Pasteur #> 87  -0.3258523027 0.2999315     Pasteur #> 88   0.6687775411 0.2999315     Pasteur #> 89  -1.6382363147 0.2999315     Pasteur #> 90   0.3062042720 0.2999315     Pasteur #> 91  -0.4745082474 0.2999315     Pasteur #> 92  -0.6798846937 0.2999315     Pasteur #> 93  -1.1865077366 0.2999315     Pasteur #> 94  -0.5011882981 0.2999315     Pasteur #> 95   0.7362448336 0.2999315     Pasteur #> 96   0.4934415622 0.2999315     Pasteur #> 97   0.9661866515 0.2999315     Pasteur #> 98   1.7212764661 0.2999315     Pasteur #> 99  -0.8199997483 0.2999315     Pasteur #> 100  0.7369163271 0.2999315     Pasteur #> 101 -0.5403439270 0.2999315     Pasteur #> 102  0.0525570079 0.2999315     Pasteur #> 103  0.4973762860 0.2999315     Pasteur #> 104  0.5434412113 0.2999315     Pasteur #> 105  1.4015048920 0.2999315     Pasteur #> 106  0.5338429790 0.2999315     Pasteur #> 107  1.5005470281 0.2999315     Pasteur #> 108 -0.4353526184 0.2999315     Pasteur #> 109  1.7269399974 0.2999315     Pasteur #> 110 -0.1863115671 0.2999315     Pasteur #> 111  0.7431541299 0.2999315     Pasteur #> 112  0.3345159128 0.2999315     Pasteur #> 113  0.3111963144 0.2999315     Pasteur #> 114  0.6750153713 0.2999315     Pasteur #> 115 -1.3822859470 0.2999315     Pasteur #> 116  0.4299090164 0.2999315     Pasteur #> 117  0.4368182853 0.2999315     Pasteur #> 118 -0.6334339242 0.2999315     Pasteur #> 119 -0.9153928519 0.2999315     Pasteur #> 120 -0.2662544424 0.2999315     Pasteur #> 121 -0.1238362896 0.2999315     Pasteur #> 122 -0.1987871727 0.2999315     Pasteur #> 123  1.5676284956 0.2999315     Pasteur #> 124 -0.2906313821 0.2999315     Pasteur #> 125  0.7125393874 0.2999315     Pasteur #> 126  0.1324998831 0.2999315     Pasteur #> 127  1.1488177518 0.2999315     Pasteur #> 128  0.5559168169 0.2999315     Pasteur #> 129  0.8572606191 0.2999315     Pasteur #> 130 -0.9789254060 0.2999315     Pasteur #> 131  1.4416206448 0.2999315     Pasteur #> 132  0.4542859333 0.2999315     Pasteur #> 133 -1.3845890506 0.2999315     Pasteur #> 134 -0.2883282757 0.2999315     Pasteur #> 135  0.4430560881 0.2999315     Pasteur #> 136  1.2089899229 0.2999315     Pasteur #> 137  1.1942112109 0.2999315     Pasteur #> 138  0.6013102486 0.2999315     Pasteur #> 139  0.2371053667 0.2999315     Pasteur #> 140  1.0053422804 0.2999315     Pasteur #> 141  0.8095640810 0.2999315     Pasteur #> 142 -1.4408264861 0.2999315     Pasteur #> 143  1.3821199900 0.2999315     Pasteur #> 144  2.7284791267 0.2999315     Pasteur #> 145  0.0123440494 0.2999315     Pasteur #> 146  0.8277032180 0.2999315     Pasteur #> 147  0.7862444827 0.2999315     Pasteur #> 148 -1.1325734026 0.2999315     Pasteur #> 149  1.7660956264 0.2999315     Pasteur #> 150 -0.3712457509 0.2999315     Pasteur #> 151  1.8944065607 0.2999315     Pasteur #> 152  0.6098511578 0.2999315     Pasteur #> 153  0.2654170028 0.2999315     Pasteur #> 154 -1.1434174113 0.2999315     Pasteur #> 155 -0.6005160981 0.2999315     Pasteur #> 156  0.3562038937 0.2999315     Pasteur #> 157 -0.3952560297 0.3152173 Grant-White #> 158 -0.6339724772 0.3152173 Grant-White #> 159  0.2006240287 0.3152173 Grant-White #> 160 -0.3424279836 0.3152173 Grant-White #> 161  0.4351919667 0.3152173 Grant-White #> 162  0.3115124621 0.3152173 Grant-White #> 163  2.1561291304 0.3152173 Grant-White #> 164 -0.2901419159 0.3152173 Grant-White #> 165 -0.0836930350 0.3152173 Grant-White #> 166 -0.0180739626 0.3152173 Grant-White #> 167 -0.3482023390 0.3152173 Grant-White #> 168 -2.1021597427 0.3152173 Grant-White #> 169 -0.6455211880 0.3152173 Grant-White #> 170 -1.4615522765 0.3152173 Grant-White #> 171  1.0262088017 0.3152173 Grant-White #> 172 -1.0506495591 0.3152173 Grant-White #> 173  0.4308707217 0.3152173 Grant-White #> 174  0.9582254779 0.3152173 Grant-White #> 175 -0.2535530327 0.3152173 Grant-White #> 176  1.4214142722 0.3152173 Grant-White #> 177 -0.9540052265 0.3152173 Grant-White #> 178  1.0029529231 0.3152173 Grant-White #> 179  1.2184135369 0.3152173 Grant-White #> 180 -1.2498710090 0.3152173 Grant-White #> 181 -0.5198466305 0.3152173 Grant-White #> 182 -0.0471041875 0.3152173 Grant-White #> 183  0.4393404762 0.3152173 Grant-White #> 184 -1.0311730096 0.3152173 Grant-White #> 185 -0.9502259332 0.3152173 Grant-White #> 186 -0.1141763435 0.3152173 Grant-White #> 187 -0.4004884068 0.3152173 Grant-White #> 188  0.1050635903 0.3152173 Grant-White #> 189 -0.3354112770 0.3152173 Grant-White #> 190 -1.5556596125 0.3152173 Grant-White #> 191 -0.8442006782 0.3152173 Grant-White #> 192  0.0780283916 0.3152173 Grant-White #> 193  0.2011659712 0.3152173 Grant-White #> 194 -2.5263954621 0.3152173 Grant-White #> 195 -0.6914909578 0.3152173 Grant-White #> 196  2.0234378663 0.3152173 Grant-White #> 197  0.9733807823 0.3152173 Grant-White #> 198  0.4204058784 0.3152173 Grant-White #> 199 -0.9260589225 0.3152173 Grant-White #> 200 -0.5669003212 0.3152173 Grant-White #> 201  0.1202188947 0.3152173 Grant-White #> 202  0.6210804306 0.3152173 Grant-White #> 203 -1.3421940527 0.3152173 Grant-White #> 204  0.1625820976 0.3152173 Grant-White #> 205 -0.0323180992 0.3152173 Grant-White #> 206  0.2444403061 0.3152173 Grant-White #> 207 -0.7443190039 0.3152173 Grant-White #> 208 -0.4379884220 0.3152173 Grant-White #> 209 -1.8529784508 0.3152173 Grant-White #> 210 -0.8256352699 0.3152173 Grant-White #> 211  1.2003900978 0.3152173 Grant-White #> 212 -0.3328743349 0.3152173 Grant-White #> 213  0.0199679685 0.3152173 Grant-White #> 214  1.6758280024 0.3152173 Grant-White #> 215 -0.7190680830 0.3152173 Grant-White #> 216 -0.2050463207 0.3152173 Grant-White #> 217  1.9621400656 0.3152173 Grant-White #> 218 -0.9345287129 0.3152173 Grant-White #> 219 -0.3534347427 0.3152173 Grant-White #> 220 -1.9580925486 0.3152173 Grant-White #> 221 -1.3602175025 0.3152173 Grant-White #> 222  0.0859562303 0.3152173 Grant-White #> 223 -0.2340765190 0.3152173 Grant-White #> 224  0.6780569596 0.3152173 Grant-White #> 225 -0.4295186317 0.3152173 Grant-White #> 226 -0.6920329003 0.3152173 Grant-White #> 227 -0.7158307215 0.3152173 Grant-White #> 228 -0.1960345878 0.3152173 Grant-White #> 229 -0.3676788793 0.3152173 Grant-White #> 230  1.7742566022 0.3152173 Grant-White #> 231 -0.6792418741 0.3152173 Grant-White #> 232  0.0760333654 0.3152173 Grant-White #> 233  1.4989512714 0.3152173 Grant-White #> 234 -0.7881352546 0.3152173 Grant-White #> 235 -1.3564381627 0.3152173 Grant-White #> 236 -0.3424279836 0.3152173 Grant-White #> 237  1.1080670102 0.3152173 Grant-White #> 238  1.0476803416 0.3152173 Grant-White #> 239  1.0224294726 0.3152173 Grant-White #> 240  0.3823639473 0.3152173 Grant-White #> 241  0.5644730554 0.3152173 Grant-White #> 242  0.7880342609 0.3152173 Grant-White #> 243  0.4308707217 0.3152173 Grant-White #> 244  0.4038355230 0.3152173 Grant-White #> 245 -0.4437627683 0.3152173 Grant-White #> 246  0.0812657691 0.3152173 Grant-White #> 247  0.1483379252 0.3152173 Grant-White #> 248  0.5392221863 0.3152173 Grant-White #> 249  0.5359848088 0.3152173 Grant-White #> 250 -0.1702417405 0.3152173 Grant-White #> 251  0.4361030987 0.3152173 Grant-White #> 252  2.2284336635 0.3152173 Grant-White #> 253  1.3648069594 0.3152173 Grant-White #> 254  0.6513529802 0.3152173 Grant-White #> 255  1.6943933841 0.3152173 Grant-White #> 256 -0.1574506784 0.3152173 Grant-White #> 257 -0.2768089380 0.3152173 Grant-White #> 258  1.8047399107 0.3152173 Grant-White #> 259 -0.0328600509 0.3152173 Grant-White #> 260  0.2154100812 0.3152173 Grant-White #> 261  0.6358664831 0.3152173 Grant-White #> 262 -0.4412257995 0.3152173 Grant-White #> 263  0.2438983636 0.3152173 Grant-White #> 264  0.9739226982 0.3152173 Grant-White #> 265  1.0061903098 0.3152173 Grant-White #> 266  0.9596785882 0.3152173 Grant-White #> 267  2.1052961106 0.3152173 Grant-White #> 268  0.9501249128 0.3152173 Grant-White #> 269  1.1403346218 0.3152173 Grant-White #> 270 -0.4152744951 0.3152173 Grant-White #> 271  0.5026333389 0.3152173 Grant-White #> 272  0.0051818802 0.3152173 Grant-White #> 273 -0.3096184562 0.3152173 Grant-White #> 274 -0.3857023185 0.3152173 Grant-White #> 275 -0.8874750488 0.3152173 Grant-White #> 276 -1.1134004701 0.3152173 Grant-White #> 277 -0.2283021636 0.3152173 Grant-White #> 278  0.1678144746 0.3152173 Grant-White #> 279 -1.1662284537 0.3152173 Grant-White #> 280 -0.4527744745 0.3152173 Grant-White #> 281 -0.6952703137 0.3152173 Grant-White #> 282  1.1655855175 0.3152173 Grant-White #> 283 -0.4908164323 0.3152173 Grant-White #> 284  0.4541265645 0.3152173 Grant-White #> 285 -0.7591050564 0.3152173 Grant-White #> 286 -0.4623281857 0.3152173 Grant-White #> 287  1.3363186770 0.3152173 Grant-White #> 288 -0.7823609350 0.3152173 Grant-White #> 289  0.1140753232 0.3152173 Grant-White #> 290 -0.2611117177 0.3152173 Grant-White #> 291 -0.5849237710 0.3152173 Grant-White #> 292 -1.4087242662 0.3152173 Grant-White #> 293 -0.2430882519 0.3152173 Grant-White #> 294 -0.1760160958 0.3152173 Grant-White #> 295 -0.7448609198 0.3152173 Grant-White #> 296 -0.1341948089 0.3152173 Grant-White #> 297 -0.7480982973 0.3152173 Grant-White #> 298 -0.9345287129 0.3152173 Grant-White #> 299  0.8873740285 0.3152173 Grant-White #> 300 -0.0566578363 0.3152173 Grant-White #> 301  0.5830384728 0.3152173 Grant-White"},{"path":"https://gengrui-zhang.github.io/R2spa/reference/tspa.html","id":null,"dir":"Reference","previous_headings":"","what":"Two-Stage Path Analysis — tspa","title":"Two-Stage Path Analysis — tspa","text":"Fit two-stage path analysis (2S-PA) model.","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/reference/tspa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two-Stage Path Analysis — tspa","text":"","code":"tspa(model, data, reliability = NULL, se = NULL, ...)"},{"path":"https://gengrui-zhang.github.io/R2spa/reference/tspa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two-Stage Path Analysis — tspa","text":"model string variable describing structural path model, lavaan syntax. data data frame containing factor scores. reliability numeric vector representing reliability indexes latent factor. Currently tspa() support reliability argument. Please use se. se numeric vector representing standard errors latent factor single-group 2S-PA. list data frame storing standard errors group latent factor multigroup 2S-PA. ... Additional arguments passed sem. See lavOptions complete list.","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/reference/tspa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two-Stage Path Analysis — tspa","text":"object class lavaan, attribute tspaModel contains model syntax.","code":""},{"path":"https://gengrui-zhang.github.io/R2spa/reference/tspa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two-Stage Path Analysis — tspa","text":"","code":"library(lavaan) ### single-group example  # get factor scores fs_dat_ind60 <- get_fs(data = PoliticalDemocracy,                        model = \"ind60 =~ x1 + x2 + x3\") fs_dat_dem60 <- get_fs(data = PoliticalDemocracy,                        model = \"dem60 =~ y1 + y2 + y3 + y4\") fs_dat <- cbind(fs_dat_ind60, fs_dat_dem60)  # tspa model tspa(model = \"dem60 ~ ind60\", data = fs_dat,      se = c(ind60 = 0.1213615, dem60 = 0.6756472)) #> lavaan 0.6.13 ended normally after 17 iterations #>  #>   Estimator                                         ML #>   Optimization method                           NLMINB #>   Number of model parameters                         3 #>  #>   Number of observations                            75 #>  #> Model Test User Model: #>                                                        #>   Test statistic                                 0.000 #>   Degrees of freedom                                 0  ### multigroup example  # get factor scores fs_dat_visual <- get_fs(data = HolzingerSwineford1939,                         model = \"visual =~ x1 + x2 + x3\",                         group = \"school\") fs_dat_speed <- get_fs(data = HolzingerSwineford1939,                        model = \"speed =~ x7 + x8 + x9\",                        group = \"school\") fs_hs <- cbind(fs_dat_visual, fs_dat_speed)  if (FALSE) { # tspa model tspa(model = \"visual ~ speed\",      data = fs_hs,      se = data.frame(visual = c(0.3391326, 0.311828),                      speed = c(0.2786875, 0.2740507)),      group = \"school\",      group.equal = \"regressions\")  # manually adding equality constraints on the regression coefficients tspa(model = \"visual ~ c(b1, b1) * speed\",      data = fs_hs,      se = list(visual = c(0.3391326, 0.311828),                speed = c(0.2786875, 0.2740507)),      group = \"school\") }"}]
