% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  man]{apa7}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{english}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\usepackage{etoolbox}
\AtBeginEnvironment{verbatim}{\small}
\usepackage{setspace}
\AtBeginEnvironment{verbatim}{\begin{singlespace}}
\AtEndEnvironment{verbatim}{\end{singlespace}}
% Add any other preamble commands or LaTeX package inclusions here
% Manuscript styling
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

% Table formatting
\usepackage{longtable}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\centering\begin{threeparttable}}
%   {\end{threeparttable}\end{landscape}}
\newenvironment{lltable}{\begin{landscape}\centering\begin{ThreePartTable}}{\end{ThreePartTable}\end{landscape}}

% Enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}

% \setlength{\parindent}{0.5in}
% \setlength{\parskip}{0pt plus 0pt minus 0pt}

% Overwrite redefinition of paragraph and subparagraph by the default LaTeX template
% See https://github.com/crsh/papaja/issues/292
\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries\itshape\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-\z@\relax}%
  {\normalfont\normalsize\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother

\makeatletter
\usepackage{etoolbox}
\patchcmd{\maketitle}
  {\section{\normalfont\normalsize\abstractname}}
  {\section*{\normalfont\normalsize\abstractname}}
  {}{\typeout{Failed to patch abstract.}}
\patchcmd{\maketitle}
  {\section{\protect\normalfont{\@title}}}
  {\section*{\protect\normalfont{\@title}}}
  {}{\typeout{Failed to patch title.}}
\makeatother

\usepackage{xpatch}
\makeatletter
\xapptocmd\appendix
  {\xapptocmd\section
    {\addcontentsline{toc}{section}{\appendixname\ifoneappendix\else~\theappendix\fi\\: #1}}
    {}{\InnerPatchFailed}%
  }
{}{\PatchFailed}
\DeclareDelayedFloatFlavor{ThreePartTable}{table}
\DeclareDelayedFloatFlavor{lltable}{table}
\DeclareDelayedFloatFlavor*{longtable}{table}
\makeatletter
\renewcommand{\efloat@iwrite}[1]{\immediate\expandafter\protected@write\csname efloat@post#1\endcsname{}}
\makeatother
\usepackage{lineno}

\linenumbers
\usepackage{csquotes}
\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-\z@\relax}%
  {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother

\usepackage{colortbl}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Methods},
  pdfauthor={Jimmy},
  pdflang={en-EN},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Methods}
\author{Jimmy\textsuperscript{}}
\date{}


\shorttitle{SHORT TITLE}

\affiliation{\phantom{0}}

\begin{document}
\maketitle

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\hypertarget{sample-source}{%
\subsection{Sample Source}\label{sample-source}}

The data was sourced from the Panel Study of Income Dynamics (PSID), the longest-running and nationally representative panel survey in the United States starting from 1968, which tracks the physical and psychological well-being of U.S. residents in the context of societal change (Institute for Social Research, 2024). As of 2015, the PSID has collected data across 39 waves over 47 years from 10,000 households and 25,000 individuals, and maintains an impressive return rate (i.e., return to study for consecutive years; 96--98\%) for nearly every wave. Designed with a longitudinal approach, the PSID ensures the continuity of data acquisition by including children of participated adults (and next generations) who establish new households (Institute for Social Research, 2024).

In this study, we used the Transition to Adulthood Supplement (TAS) from PSID collected in the 2019 wave (TAS2019). TAS2019 provides a rich dataset including variables related to psychological functioning, family formation, fertility-related behavior, cohabitation, childhood adversity, and health condition for the cohort aged 18 to 28 years. The TAS2019 sample eligibility was determined based on three key criteria: (1) Participants were aged between 18 and 28 years in 2019; (2) Participants' families were required to participate in the 2019 Core PSID interview; (3) A prerequisite of completing a 2017 Core PSID interview was required specifically for the 2017 immigrant refresher sample (Panel Study of Income Dynamics {[}Transition into Adulthood Supplement{]}, Public Use Dataset, 2019). The dataset had a sample size of 2,595 individuals, with 1,201 males and 1,352 females. More details of this sample are available in the codebook of TAS2019.

\hypertarget{measures}{%
\subsection{Measures}\label{measures}}

All psychological constructs of interest were measured by scales with multiple items. The internal consistency measures (Cronbach's \(\alpha\)) for each scale were reported and found exceeding the acceptable threshold (i.e., \(\alpha > .70\)) for analyses (Nunnally \& Bernstein, 1994).

\hypertarget{depression}{%
\subsubsection{Depression}\label{depression}}

Depression was evaluated by the PHQ-9 Depression screening scale (Patent Health Questionnaire; Kroenke, Spitzer, \& Williams, 2001) in which various depressive symptoms were assessed such as depressed mood, sleeping trouble, fatigue, concentration problems, and psychomotor failures. The scale had 9 items, each with four response categories. For example, participants had four options for the item ``Over the last two weeks, how often have you been bothered by?'' {[}1 = ``Not at all''; 2 = ``Several days''; 3 = ``More than half the days''; 4 = ``Nearly every day''{]}. Participants who chose either ``Don't know'' or ``NA; refused'' were considered missing and their responses were excluded from the subsequent analyses. The data had 110 records of missing (0.47\%), and the reliability estimate for PHQ-9 was \(\alpha = .87\).

\hypertarget{perceived-everyday-discrimination-ped}{%
\subsubsection{Perceived Everyday Discrimination (PED)}\label{perceived-everyday-discrimination-ped}}

The Everyday Discrimination Scale (EDD; Williams et al., 1997) used in the PSID study comprehensively measured frequency of perceived discrimination regarding daily interpersonal communications, perceived violations of equal rights, and experiences associated with less courtesy and ill-respect. The scale was composed of 7 items, each having six response categories. One example item, ``You are treated with less respect than other people'', had six response categories with {[}1 = ``Never''; 2 = ``Less than once a year''; 3 = ``A few times a year''; 4 = ``A few times a month''; 5 = ``At least once a week''; 6 = ``Almost every day''{]}. Invalid responses were ``Don't know'' and ``NA'', similar to PHQ-9, and coded as missing (1.98\%). The reliability for EDD was \(\alpha = .90\).

\hypertarget{self-esteem}{%
\subsubsection{Self-Esteem}\label{self-esteem}}

Self-esteem was assessed by Rosenberg Self-Esteem Scale (RSE; Rosenberg, 1965), originally designed to measure the global self-worth through both positive and negative feelings about one's self. The scale consists of ten items, each with four options. Five items are positively oriented (e.g., ``I feel that I have a number of good qualities.'') with response options of {[}1 = ``Strongly disagree''; 2 = ``Disagree''; 3 = ``Agree''; 4 = ``Strongly agree''{]}, while the other five items are negatively oriented (e.g., ``I certainly feel useless at times''). For congruent interpretation, response options of negatively oriented items were reversely coded (i.e., 1 was recoded as 4; 2 was recoded as 3; 3 was recoded as 2; 4 was recoded as 1). Accordingly, higher scores on this scale indicated a higher level of self-esteem. The internal consistency for RSE was \(\alpha = .88\).

\hypertarget{analytical-methods-and-procedure}{%
\subsection{Analytical Methods and Procedure}\label{analytical-methods-and-procedure}}

In this section, we showed how to test the hypothetical models in Figure 1-3 and estimate the latent interaction effect of self-esteem on the relation between PED and depression, using matched-pair UPI, RAPI and 2S-PA-Int with step-by-step demonstrations. In summary, the first-order latent variables included a predictor (PED) indicated by 7 items (PED1 \textasciitilde{} PED7), a moderator (self-esteem) indicated by 10 items (SelfE1 \textasciitilde{} SelfE10), and a dependent variable (depression) indicated by 9 items (PHQ1 \textasciitilde{} PHQ9). For each method, the model fitting procedure was conducted based on the \texttt{sem} function in the R package \texttt{lavaan} (Rosseel, 2012). To simplify the demonstration steps, we have already pre-processed the data of three latent variables by selecting only relevant indicators from TAS2019 and renaming latent variables as \texttt{PED}, \texttt{SelfE}, and \texttt{PHQ} (for perceived every discrimination, self-esteem, and depression, respectively). A full data frame was then created with a name \texttt{dat}:

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Dimension of dat: 2,595 observations and 26 first{-}order indicators}
\NormalTok{dat }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(PED, SelfE, PHQ)}
\end{Highlighting}
\end{Shaded}

\normalsize

\hypertarget{matched-pair-upi}{%
\subsubsection{Matched-pair UPI}\label{matched-pair-upi}}

For matched-pair UPI, We began the demonstration with forming PIs by mean-centering all the first-order indicators and renaming the full dataset as \texttt{dat.centered}:

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Mean{-}centering first{-}order indicators of PED and SelfE}
\NormalTok{dat.centered }\OtherTok{\textless{}{-}}\NormalTok{ dat }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\AttributeTok{.cols =} \FunctionTok{everything}\NormalTok{(), }\AttributeTok{.fns =} \SpecialCharTok{\textasciitilde{}}\NormalTok{.x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(.x, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\normalsize
Note that the argument \texttt{na.rm} was set to \texttt{TRUE} for the dataset with missing values. Then, we used the mean-centered first-order indicators to form PIs. Given that the numbers of indicators for PED and self-esteem were unequal, a forming strategy needed to be determined for use. According to Marsh et al.~(2004), the authors suggested one solution in which items could be matched in terms of quality, which was echoed by Wu et al.~(2013) such that PIs should be formed by using highly reliable first-order indicators (i.e., items with higher factor loadings) and ignoring those with low reliability. Therefore we fitted two unidimensional confirmatory factor analysis (CFA) models to the indicators of PED and self-esteem, and decreasingly sorted the factor loadings. Following the instruction from Wu et al.~(2013), first 7 indicators of self-esteem with highest factor loadings were chosen to pair with the indicators of PED to form PIs. The chosen pairs of indicators were listed below:

\footnotesize

\begin{verbatim}
##     SelfE SelfE Loading  PED PED Loading
## 1 SelfE10         0.719 PED6       1.312
## 2  SelfE9         0.712 PED3       1.229
## 3  SelfE6         0.557 PED7       1.225
## 4  SelfE7         0.555 PED1       1.141
## 5  SelfE5         0.541 PED5       0.871
## 6  SelfE3         0.518 PED2       0.832
## 7  SelfE8         0.515 PED4       0.808
\end{verbatim}

\normalsize
Lin et al.~(2010) proposed a double-mean-centering (DMC) strategy to show that the mean structure of UPI methods is unnecessary and can be removed for simpler model specification and estimation, by additionally mean-centering PIs. Besides, the DMC strategy is superior under violation of normality assumption on latent variables. Then, the formed PIs were additionally mean-centered based on the DMC strategy to drop the mean structure required by matched-pair UPI. We only showed one example of formed PI for limited space, but the other PI pairs should be created using the same procedure:

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Mean{-}center formed PI}
\NormalTok{PED6.SelfE10 }\OtherTok{\textless{}{-}}\NormalTok{ dat.centered}\SpecialCharTok{$}\NormalTok{PED6 }\SpecialCharTok{*}\NormalTok{ dat.centered}\SpecialCharTok{$}\NormalTok{SelfE10 }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(dat.centered}\SpecialCharTok{$}\NormalTok{PED6 }\SpecialCharTok{*}
\NormalTok{    dat.centered}\SpecialCharTok{$}\NormalTok{SelfE10, }\AttributeTok{na.rm =}\NormalTok{ T)}
\end{Highlighting}
\end{Shaded}

\normalsize

Jorgensen et al.~(2022) introduced a R package \texttt{semTools} in which the function \texttt{IndProd()} was developed to automate the process of forming PIs with the DMC setting available. Assuming the data frame \texttt{dat.matchpair} was already created with all the mean-centered first-order indicators and 7 newly formed PIs, a \texttt{lavaan} model syntax should be created for model specification to test the latent interaction between PED and self-esteem, :

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Model Specification}
\NormalTok{model.matchpair }\OtherTok{\textless{}{-}} \StringTok{"\# Measurement model}
\StringTok{                      PHQ =\textasciitilde{} PHQ1 + PHQ2 + PHQ3 + PHQ4 + PHQ5 + PHQ6 + PHQ7 + PHQ8 + PHQ9}
\StringTok{                      PED =\textasciitilde{} PED6 + PED3 + PED7 + PED1 + PED5 + PED2 + PED4}
\StringTok{                      SelfE =\textasciitilde{} SelfE10 + SelfE9 + SelfE6 + SelfE7 + SelfE5 + SelfE3 + SelfE8}
\StringTok{                      PED.SelfE =\textasciitilde{} PED6.SelfE10 + PED3.SelfE9 + PED7.SelfE6 + PED1.SelfE7 + }
\StringTok{                                   PED5.SelfE5 + PED2.SelfE3 + PED4.SelfE8}
\StringTok{                    \# Structural model}
\StringTok{                      PHQ \textasciitilde{} PED + SelfE + PED.SelfE"}
\CommentTok{\# Model Fitting}
\NormalTok{fit.matchpair }\OtherTok{\textless{}{-}} \FunctionTok{sem}\NormalTok{(}\AttributeTok{data =}\NormalTok{ dat.matchpair, }\AttributeTok{model =}\NormalTok{ model.matchpair)}
\end{Highlighting}
\end{Shaded}

\normalsize
The measurement model was specified using \texttt{lavaan} syntax as regular CFA models, in which the latent interaction term, \texttt{PED.SelfE}, was indicated by the matched-pair PIs. The specification of the structural model was in the usual regression form, and the model fitting was conducted using the \texttt{sem} function in \texttt{lavaan}. According to DMC, the mean structure for the first-order latent predictors and the latent interaction term was not needed, so that the argument of \texttt{meanstructure} was not required when applying the \texttt{sem} function.

\hypertarget{rapi}{%
\subsubsection{RAPI}\label{rapi}}

One of the critical differences between RAPI and matched-pair UPI was that matched-pair UPI used multiple indicators for the latent variables while RAPI used composite scores (sum or mean scores), so that RAPI produced a simpler model specification. In this study, we demonstrated RAPI using mean scores as single indicators of latent variables.

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute composite scores using first{-}order indicators}
\NormalTok{dat.centered }\OtherTok{\textless{}{-}}\NormalTok{ dat.centered }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{PED.mean =} \FunctionTok{rowMeans}\NormalTok{(}\FunctionTok{select}\NormalTok{(., }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"PED"}\NormalTok{)), }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{),}
         \AttributeTok{SelfE.mean =} \FunctionTok{rowMeans}\NormalTok{(}\FunctionTok{select}\NormalTok{(., }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"SelfE"}\NormalTok{)), }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{),}
         \AttributeTok{PHQ.mean =} \FunctionTok{rowMeans}\NormalTok{(}\FunctionTok{select}\NormalTok{(., }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"PHQ"}\NormalTok{)), }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{),}
         \AttributeTok{PED.SelfE.mean =}\NormalTok{ PED.mean}\SpecialCharTok{*}\NormalTok{SelfE.mean }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(PED.mean}\SpecialCharTok{*}\NormalTok{SelfE.mean, }\AttributeTok{na.rm =}\NormalTok{ T))}
\end{Highlighting}
\end{Shaded}

\normalsize
We first computed mean scores using the first-order indicators and the computed SIs were \texttt{PED.mean}, \texttt{SelfE.mean}, \texttt{PHQ.mean} for their latent variables. Then we multiplied \texttt{PED.mean} and \texttt{SelfE.mean} to create the SI for the latent interaction term ,\texttt{PED.SelfE.mean}, and mean-centered it again to apply the DMC strategy.

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Model Specification}
\NormalTok{model.rapi }\OtherTok{\textless{}{-}} \StringTok{"\# Measurement model}
\StringTok{                 PHQ =\textasciitilde{} 1*PHQ.mean}
\StringTok{                 PED =\textasciitilde{} 1*PED.mean}
\StringTok{                 SelfE =\textasciitilde{} 1*SelfE.mean}
\StringTok{                 PED.SelfE =\textasciitilde{} 1*PED.SelfE.mean}
\StringTok{               \# Error variance}
\StringTok{                 PED.mean \textasciitilde{}\textasciitilde{} ev1*PED.mean}
\StringTok{                 SelfE.mean \textasciitilde{}\textasciitilde{} ev2*SelfE.mean}
\StringTok{                 PED.SelfE.mean \textasciitilde{}\textasciitilde{} ev3*PED.SelfE.mean}
\StringTok{               \# Latent variance}
\StringTok{                 PED \textasciitilde{}\textasciitilde{} v1*PED}
\StringTok{                 SelfE \textasciitilde{}\textasciitilde{} v2*SelfE}
\StringTok{                 PED.SelfE \textasciitilde{}\textasciitilde{} v3*PED.SelfE}
\StringTok{               \# Error Constraints}
\StringTok{                 ev1 == (1 {-} 0.8965932) * v1 / 0.8965932}
\StringTok{                 ev2 == (1 {-} 0.8792078) * v2 / 0.8792078}
\StringTok{                 ev3 == ev1 * v2 + ev2 * v1 + ev1 * ev2}
\StringTok{               \# Structural model}
\StringTok{                 PHQ \textasciitilde{} PED + SelfE + PED.SelfE"}
\CommentTok{\# Model Fitting}
\NormalTok{fit.rapi }\OtherTok{\textless{}{-}} \FunctionTok{sem}\NormalTok{(}\AttributeTok{data =}\NormalTok{ dat.centered, }\AttributeTok{model =}\NormalTok{ model.rapi)}
\end{Highlighting}
\end{Shaded}

\normalsize

In the measurement model, the factor loadings of single indicators on the latent variables were all constrained to 1. As described in the introduction, the error variances of single indicators were constrained to account for measurement error and specified in the section of \texttt{Error\ Constraints}. Take PED as an example, the constraint for \texttt{PED.mean} could be derived as a function of estimated reliability, such that \(ev_{1} = [(1 - \rho_{PED})/{\rho_{PED}}]v_{1}\) where \(\rho_{PED} = 0.8965932\) was the estimated reliability of PED using Cronbach's \(\alpha\), and \(v_{1}\) was the sample-estimated latent variance of PED. The same formula was applied to self-esteem to generate its error-variance constraint. Note that researchers could use any reasonable reliability measures depending on their research design and data. As a reference, Hsiao et al.~(2018) compared four reliability measures between Cronbach's \(\alpha\) (Cronbach, 1951), \(\omega\) (McDonald, 1970; Raykov, 1997), the greatest lower bound reliability (GLB; Berge \& Sočan, 2004), and Coefficient H (Hancock \& Mueller, 2001), and found that Cronbach's \(\alpha\) was adequate to account for measurement error and adjust for biased interaction estimates.
Then, the error-variance constraint of \texttt{PED.SelfE} could be derived using the formula \(ev_{3} = ev_{1}v_{2} + ev_{2}v_{1} + ev_{1}ev_{2}\) where \(v_{2}\) and \(ev_{2}\) were the variance of self-esteem and the error-variance constraint of \texttt{SelfE.mean}. More technical details of formula derivation about \(ev_{3}\) were available in Appendix A of Hsiao et al.~(2018).

\hypertarget{s-pa-int}{%
\subsubsection{2S-PA-Int}\label{s-pa-int}}

As described in the introduction, 2S-PA-Int involved a two-step process by separately estimating the measurement and the structural models. In this example, we continued to use the dataset \texttt{dat.centered} which contained the original first-order indicators to create a new data frame with factor scores, namely \texttt{dat.fs}.

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute factor scores}
\NormalTok{model.fs }\OtherTok{\textless{}{-}} \StringTok{"PHQ =\textasciitilde{} PHQ1 + PHQ2 + PHQ3 + PHQ4 + PHQ5 + PHQ6 + PHQ7 + PHQ8 + PHQ9}
\StringTok{             PED =\textasciitilde{} PED1 + PED2 + PED3 + PED4 + PED5 + PED6 + PED7}
\StringTok{             SelfE =\textasciitilde{} SelfE1 + SelfE2 + SelfE3 + SelfE4 + SelfE5 + }
\StringTok{                      SelfE6 + SelfE7 + SelfE8 + SelfE9 + SelfE10"}
\NormalTok{dat.fs }\OtherTok{\textless{}{-}} \FunctionTok{get\_fs}\NormalTok{(dat.centered,}
                 \AttributeTok{model =}\NormalTok{ model.fs,}
                 \AttributeTok{method =} \StringTok{"Bartlett"}\NormalTok{,}
                 \AttributeTok{std.lv =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize
First, the model syntax named \texttt{model.fs} represented the structure of measurement model under the confirmatory factor analysis (CFA) framework, wherein each latent variable, PHQ, PED, and SelfE, was indicated by their corresponding first-order indicators. Next, a user-defined function \texttt{get\_fs()}, created by Lai et al.~(2024), was used to compute factor scores with corresponding standard errors of measurement. The argument \texttt{method} indicated the computation methods of factor scores. Currently the function is able to support \texttt{regression} or \texttt{Bartlett} factor scores. Technically, the factor scores could be estimated using any appropriate psychometric methods. We used Bartlett factor scores in this demonstration as Estabrook and Neale (2013) mentioned that Bartlett's method corrected the regression method by correcting the bias in factor means. The \texttt{std.lv} argument was set to \texttt{TRUE} so that the variances of latent variables were set to unity because latent variables did not have meaningful units naturally (Lai \& Hsiao, 2021).

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# obtain the single indicators}
\NormalTok{dat.fs }\OtherTok{\textless{}{-}}\NormalTok{ dat.fs[, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{]}
\FunctionTok{colnames}\NormalTok{(dat.fs) }\OtherTok{\textless{}{-}} \FunctionTok{gsub}\NormalTok{(}\StringTok{"\_"}\NormalTok{, }\StringTok{"."}\NormalTok{, }\FunctionTok{colnames}\NormalTok{(dat.fs))}
\end{Highlighting}
\end{Shaded}

\normalsize

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Obtain the factor scores as single indicators }
\NormalTok{dat.fs}\SpecialCharTok{$}\NormalTok{fs.PED.SelfE }\OtherTok{\textless{}{-}}\NormalTok{ dat.fs}\SpecialCharTok{$}\NormalTok{fs.PED}\SpecialCharTok{*}\NormalTok{dat.fs}\SpecialCharTok{$}\NormalTok{fs.SelfE}
\NormalTok{dat.fs}\SpecialCharTok{$}\NormalTok{fs.PED.SelfE }\OtherTok{\textless{}{-}}\NormalTok{ dat.fs}\SpecialCharTok{$}\NormalTok{fs.PED.SelfE }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(dat.fs}\SpecialCharTok{$}\NormalTok{fs.PED.SelfE)}
\CommentTok{\# Compute the standard error of interaction}
\NormalTok{dat.fs}\SpecialCharTok{$}\NormalTok{fs.PED.SelfE.se }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1}\SpecialCharTok{*}\NormalTok{dat.fs}\SpecialCharTok{$}\NormalTok{fs.PED.se[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{*}\NormalTok{dat.fs}\SpecialCharTok{$}\NormalTok{fs.SelfE.se[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+} 
\NormalTok{                               dat.fs}\SpecialCharTok{$}\NormalTok{fs.PED.se[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{*}\NormalTok{dat.fs}\SpecialCharTok{$}\NormalTok{fs.SelfE.se[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\normalsize

The creation of SI to the latent interaction term \texttt{fs.PED.SelfE} was very similar to what was done in RAPI, such that the factor scores of PED and SelfE were multiplied and then mean-centered subsequently. Furthermore, the formula for computing the standard error of measurement of \texttt{fs.PED.SelfE} was the same as the one used in RAPI. Since PED and self-esteem's latent variances were set to 1 when computing the factor scores, the formula only involved in their standard error of measurement, namely \texttt{fs.PED.se} and \texttt{fs.SelfE.se}.

\footnotesize

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Model Specification}
\NormalTok{model}\FloatTok{.2}\NormalTok{spaint }\OtherTok{\textless{}{-}} \StringTok{"\# Measurement model}
\StringTok{                    PHQ =\textasciitilde{} 1*fs.PHQ}
\StringTok{                    PED =\textasciitilde{} 1*fs.PED}
\StringTok{                    SelfE =\textasciitilde{} 1*fs.SelfE}
\StringTok{                    PED.SelfE =\textasciitilde{} 1*fs.PED.SelfE}
\StringTok{                  \# Error variance}
\StringTok{                    fs.PED \textasciitilde{}\textasciitilde{} 0.09875111*fs.PED}
\StringTok{                    fs.SelfE \textasciitilde{}\textasciitilde{} 0.3397634*fs.SelfE}
\StringTok{                    fs.PED.SelfE \textasciitilde{}\textasciitilde{} 0.22559*fs.PED.SelfE}
\StringTok{                  \# Structural model}
\StringTok{                    PHQ \textasciitilde{} PED + SelfE + PED.SelfE"}
\CommentTok{\# Model Fitting}
\NormalTok{fit}\FloatTok{.2}\NormalTok{spaint }\OtherTok{\textless{}{-}} \FunctionTok{sem}\NormalTok{(}\AttributeTok{data =}\NormalTok{ dat.fs, }\AttributeTok{model =}\NormalTok{ model}\FloatTok{.2}\NormalTok{spaint)}
\end{Highlighting}
\end{Shaded}

\normalsize
Lai and Hsiao (2021) stated that 2S-PA was similar to RAPI when the indicators were treated as continuous with normal distributions. When using Bartlett scores, the model of 2S-PA-Int was similarly specified as that of RAPI, but with more simplicity because the standard errors of measurement were computed in the first stage. Thus, the input of constraints for factor loadings and error variances were even clearer and more straightforward. The standardization of coefficients was the same as UPI and RAPI.


\end{document}
