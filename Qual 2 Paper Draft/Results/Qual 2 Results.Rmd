---
title             : "Results"

author: 
  - name          : "Jimmy"

bibliography      : "r-references.bib"

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
header-includes   :
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother
  - \usepackage{colortbl}

csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
documentclass     : "apa7"
output:
  papaja::apa6_pdf:
    includes:
      in_header: "/Users/jimmy_z/R Projects/R2spa/Qual 2 Paper Draft/header.tex"

---

```{r setup, include = FALSE}
# Load packages
library("papaja")
library(formatR)
library(knitr)
library(kableExtra)
library(haven)
library(dplyr)
library(tidyr)
library(psych)
library(semTools)
library(cowplot)
library(lavaan)
library(emmeans)
library(ggplot2)
library(gridExtra)
library(R2spa)
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
opts_chunk$set(out.extra='size=\\small')
```

```{r methods code, include=FALSE}
TA2019 <- zap_formats(zap_labels(read_sav("/Users/jimmy_z/R Projects/R2spa/Qual 2 Paper Draft/TA2019.sav")))

# Scale 1: ROSENBURG SELF-ESTEEM SCALE
# Recoded items: TA190106, TA190108, TA190111, TA190112, TA190113
# Strongly agree - 4; Agree - 3; Disagree - 2; Strongly Disagree - 1; Missing - 9.
SelfE <- TA2019 %>%
  select(TA190104:TA190113) %>%
  mutate(TA190106 = recode(TA190106, "1" = "4", "2" = "3", "3" = "2", "4" = "1", "9" = "9"),
         TA190108 = recode(TA190108, "1" = "4", "2" = "3", "3" = "2", "4" = "1", "9" = "9"),
         TA190111 = recode(TA190111, "1" = "4", "2" = "3", "3" = "2", "4" = "1", "9" = "9"),
         TA190112 = recode(TA190112, "1" = "4", "2" = "3", "3" = "2", "4" = "1", "9" = "9"),
         TA190113 = recode(TA190113, "1" = "4", "2" = "3", "3" = "2", "4" = "1", "9" = "9")) %>%
  mutate_if(is.character, as.numeric) %>%
  mutate_all(na_if, 9)
colnames(SelfE) <- paste0("SelfE", 1:10)

# Scale 2: Everyday Discrimination
# No recoded items
# Never - 1; Less than once a year - 2; A few times a year - 3; A few times a month - 4;
# At least once a week - 5; Almost every day - 6; Missing - 9.
PED <- TA2019 %>%
  select(TA192066:TA192072) %>%
  mutate_all(na_if, 9) %>%
  mutate_all(na_if, 8)
colnames(PED) <- paste0("PED", 1:7)

# Scale 3: PHQ-9 Depression Scale
# No recoded items
# Not at all - 1; Several days - 2; More than half the days - 3; Nearly every day - 4; Missing - 9.
PHQ <- TA2019 %>%
  select(TA190114:TA190122) %>%
  mutate_all(na_if, 9) %>%
  mutate_all(na_if, 8)
colnames(PHQ) <- paste0("PHQ", 1:9)

# Dimension of dat: 2,595 observations and 26 first-order indicators
dat <- cbind(PED, SelfE, PHQ)
# Mean-centering first-order indicators of PED and SelfE
dat.centered <- dat %>%
       mutate(across(.cols = everything(), .fns = ~ .x - mean(.x, na.rm = TRUE)))
dat.matchpair <- indProd(dat.centered,
                       var1 = c("PED6", "PED3", "PED7", "PED1", "PED5", "PED2", "PED4"),
                       var2 = c("SelfE10", "SelfE9", "SelfE6", "SelfE7", "SelfE5", "SelfE3", "SelfE8"),
                       match = TRUE, 
                       meanC = FALSE, 
                       residualC = FALSE, 
                       doubleMC = TRUE) 
# Model Specification
model.matchpair <- "# Measurement model
                      PHQ =~ PHQ1 + PHQ2 + PHQ3 + PHQ4 + PHQ5 + PHQ6 + PHQ7 + PHQ8 + PHQ9
                      PED =~ PED6 + PED3 + PED7 + PED1 + PED5 + PED2 + PED4
                      SelfE =~ SelfE10 + SelfE9 + SelfE6 + SelfE7 + SelfE5 + SelfE3 + SelfE8
                      PED.SelfE =~ PED6.SelfE10 + PED3.SelfE9 + PED7.SelfE6 + PED1.SelfE7 + 
                                   PED5.SelfE5 + PED2.SelfE3 + PED4.SelfE8
                    # Latent variance
                      PED ~~ v1*PED
                      SelfE ~~ v2*SelfE
                      PED.SelfE ~~ v3*PED.SelfE
                    # Latent covariance
                      PED ~~ v12*SelfE
                      PED ~~ v13*PED.SelfE
                      SelfE ~~ v23*PED.SelfE
                    # Residual variance of DV
                      PHQ ~~ v4*PHQ
                    # Structural model
                      PHQ ~ g1*PED + g2*SelfE + g3*PED.SelfE
                    # Standardized
                      v_y := g1^2*v1 + g2^2*v2 + g3^2*v3 + 2*g1*g2*v12 + 
                             2*g1*g3*v13 + 2*g2*g3*v23 + v4
                      gamma1 := g1*sqrt(v1)/sqrt(v_y)
                      gamma2 := g2*sqrt(v2)/sqrt(v_y)
                      gamma3 := g3*sqrt(v1)*sqrt(v2)/sqrt(v_y)"
# Model Fitting
fit.matchpair <- sem(data = dat.matchpair,
                     model = model.matchpair)
# Compute composite scores using first-order indicators
dat.centered <- dat.centered %>%
  mutate(
    PED.mean = rowMeans(select(., starts_with("PED")), na.rm = TRUE),
    SelfE.mean = rowMeans(select(., starts_with("SelfE")), na.rm = TRUE),
    PHQ.mean = rowMeans(select(., starts_with("PHQ")), na.rm = TRUE),
    PED.SelfE.mean = PED.mean*SelfE.mean - mean(PED.mean*SelfE.mean, na.rm = T)
  )
# Model Specification
model.rapi <- "# Measurement model
                 PHQ =~ 1*PHQ.mean
                 PED =~ 1*PED.mean
                 SelfE =~ 1*SelfE.mean
                 PED.SelfE =~ 1*PED.SelfE.mean
               # Error variance
                 PED.mean ~~ ev1*PED.mean
                 SelfE.mean ~~ ev2*SelfE.mean
                 PED.SelfE.mean ~~ ev3*PED.SelfE.mean
               # Latent variance
                 PED ~~ v1*PED
                 SelfE ~~ v2*SelfE
                 PED.SelfE ~~ v3*PED.SelfE
               # Error Constraints
                 ev1 == (1 - 0.8965932) * v1 / 0.8965932
                 ev2 == (1 - 0.8792078) * v2 / 0.8792078
                 ev3 == ev1 * v2 + ev2 * v1 + ev1 * ev2
               # Latent covariance
                 PED ~~ v12*SelfE
                 PED ~~ v13*PED.SelfE
                 SelfE ~~ v23*PED.SelfE
               # Residual variance of DV
                 PHQ ~~ v4*PHQ
               # Structural model
                 PHQ ~ g1*PED + g2*SelfE + g3*PED.SelfE
               # Standardized
                 v_y := g1^2*v1 + g2^2*v2 + g3^2*v3 + 2*g1*g2*v12 + 
                        2*g1*g3*v13 + 2*g2*g3*v23 + v4
                 gamma1 := g1*sqrt(v1)/sqrt(v_y)
                 gamma2 := g2*sqrt(v2)/sqrt(v_y)
                 gamma3 := g3*sqrt(v1)*sqrt(v2)/sqrt(v_y)"
# Model Fitting
fit.rapi <- sem(data = dat.centered,
                model = model.rapi)
# Compute factor scores
model.fs <- "PHQ =~ PHQ1 + PHQ2 + PHQ3 + PHQ4 + PHQ5 + PHQ6 + PHQ7 + PHQ8 + PHQ9
             PED =~ PED1 + PED2 + PED3 + PED4 + PED5 + PED6 + PED7
             SelfE =~ SelfE1 + SelfE2 + SelfE3 + SelfE4 + SelfE5 + 
                      SelfE6 + SelfE7 + SelfE8 + SelfE9 + SelfE10"
dat.fs <- get_fs(dat.centered,
                 model = model.fs,
                 method = "Bartlett",
                 std.lv = TRUE)
# obtain the single indicators 
dat.fs <- dat.fs[ ,1:6]
colnames(dat.fs) <- gsub("_", ".", colnames(dat.fs))
# Obtain the factor scores as single indicators 
dat.fs$fs.PED.SelfE <- dat.fs$fs.PED*dat.fs$fs.SelfE
dat.fs$fs.PED.SelfE <- dat.fs$fs.PED.SelfE - mean(dat.fs$fs.PED.SelfE)
# Compute the standard error of interaction
dat.fs$fs.PED.SelfE.se <- sqrt(1*dat.fs$fs.PED.se[1]^2 + 1*dat.fs$fs.SelfE.se[1]^2 + 
                               dat.fs$fs.PED.se[1]^2*dat.fs$fs.SelfE.se[1]^2)
# Model Specification
model.2spaint <- "# Measurement model
                    PHQ =~ 1*fs.PHQ
                    PED =~ 1*fs.PED
                    SelfE =~ 1*fs.SelfE
                    PED.SelfE =~ 1*fs.PED.SelfE
                  # Error variance
                    fs.PED ~~ 0.09875111*fs.PED
                    fs.SelfE ~~ 0.3397634*fs.SelfE
                    fs.PED.SelfE ~~ 0.22559*fs.PED.SelfE
                  # Latent variance
                    PED ~~ v1*PED
                    SelfE ~~ v2*SelfE
                    PED.SelfE ~~ v3*PED.SelfE
                  # Latent covariance
                    PED ~~ v12*SelfE
                    PED ~~ v13*PED.SelfE
                    SelfE ~~ v23*PED.SelfE
                  # Residual variance of DV
                    PHQ ~~ v4*PHQ
                  # Structural model
                    PHQ ~ b1*PED + b2*SelfE + b3*PED.SelfE
                  # Standardized
                    v_y := b1^2*v1 + b2^2*v2 + b3^2*v3 + 2*b1*b2*v12 + 
                           2*b1*b3*v13 + 2*b2*b3*v23 + v4
                    beta1 := b1*sqrt(v1)/sqrt(v_y)
                    beta2 := b2*sqrt(v2)/sqrt(v_y)
                    beta3 := b3*sqrt(v1)*sqrt(v2)/sqrt(v_y)"
# Model Fitting
fit.2spaint <- sem(data = dat.fs,
                   model = model.2spaint)
```

# Results

The results of using the three methods of estimating the moderating effect of self-esteem on the relation between PED and depression were discussed below. For model fit indexes, the matched-pair UPI model showed a marginally acceptable fit with $\chi^2(df) = 4068.36(399)$, RMSEA = .06, CFI = .89, SRMR = .04, wherein $\chi^2$ was significant with $\textit{p} < .000$. Theoretically a significant $\chi^2$ indicated that the matched-pair UPI model did not fit data well, implying that there were significant discrepancies between the observed and model-implied covariance matrices. However, the sensitivity of $\chi^2$ to sample size has been a well-known issue such that even trivial discrepancies between two matrices could result in significant value, especially with a large dataset (Hu & Bentler, 1999). As for the other indexes, only CFI was slightly below the acceptable value .90, while RMSEA and SRMR were below the acceptable values .08 and .05, respectively (Browne & Cudeck, 1993; Jöreskog & Sörbom, 1993). Overall, matched-pair UPI was a reasonably acceptable method in terms of model fit. The model fit evaluation was not meaningful for RAPI and 2S-PA-Int in this study because their models were just-identified, meaning that fit indices were not informative as there were no discrepancies between observed and model-implied covariance matrices. Thus, we mainly compared the methods on their substantive estimates of path coefficients.

Before the comparison, standardized path coefficients should be computed in order to appropriately compare the relative strengths of latent predictors regardless of original units of measurement and interpret the results. Wu et al. (2011) derived the formula of standardizing path coefficients. In the context of the current study, the formula of standardization for the latent interaction estimate was 
\begin{equation}
\gamma_{3}'' = \gamma_{3} \frac{\hat{\sigma}_{\xi_{PED}}\hat{\sigma}_{\xi_{SelfE}}}{\hat{\sigma}_{PHQ}},
\end{equation}
in which $\gamma_{3}''$ was the appropriately standardized coefficient and  $\gamma_{3}$ was the original coefficient of the interaction estimate. $\hat{\sigma}_{\xi_{PED}}$, $\hat{\sigma}_{\xi_{SelfE}}$ were square root of the sample-estimated true variances (i.e., variances excluding measurement error) of first-order latent predictors, while $\hat{\sigma}_{PHQ}$ was square root of the dependent variable's total variance. The formulas for first-order effects were simpler: $\gamma_{1}'' = \gamma_{1}\hat{\sigma}_{\xi_{PED}}/\hat{\sigma}_{PHQ}$ and $\gamma_{2}'' = \gamma_{2}\hat{\sigma}_{\xi_{SelfE}}/\hat{\sigma}_{PHQ}$, where $\gamma_{1}''$ and $\gamma_{2}''$ were standardized coefficients of `PED` and `SelfE`. To implement the appropriate standardization procedure in R, an example syntax on structural model was demonstrated below:

```{r model example, echo=TRUE, eval=FALSE}
"# Latent variance
   PED ~~ v1*PED
   SelfE ~~ v2*SelfE
   PED.SelfE ~~ v3*PED.SelfE
 # Latent covariance
   PED ~~ v12*SelfE
   PED ~~ v13*PED.SelfE
   SelfE ~~ v23*PED.SelfE
 # Residual variance of DV
   PHQ ~~ v4*PHQ
 # Structural model
   PHQ ~ g1*PED + g2*SelfE + g3*PED.SelfE
 # Standardized
   vy := g1^2*v1 + g2^2*v2 + g3^2*v3 + 2*g1*g2*v12 + 
         2*g1*g3*v13 + 2*g2*g3*v23 + v4
   gamma1 := g1*sqrt(v1)/sqrt(vy)
   gamma2 := g2*sqrt(v2)/sqrt(vy)
   gamma3 := g3*sqrt(v1)*sqrt(v2)/sqrt(vy)"
```
We added user-defined labels for unstandardized path coefficients (i.e., $g_{1}$, $g_{2}$, and $g_{3}$) and standardized coefficients (i.e., $\gamma_{1}$, $\gamma_{2}$, and $\gamma_{3}$), where standardized coefficients were defined using latent variables' sample-estimated variances (i.e., $v_{1}$, $v_{2}$, $v_{3}$, and $v_{y}$). Since there was no way to directly label total variance of the dependent variable in `lavaan`, we used $v_{4}$ to indicate the residual variance of PHQ, $\hat{\zeta}_{PHQ}$. Considering $\xi_{PED}$ and $\xi_{SelfE}$ were allowed to correlate in our hypothetical model, we further used labels to indicate the covariances between latent variables (i.e., $v12$, $v_{13}$, and $v_{23}$). Then the total variance of PHQ, $v_{y}$, could be specified using unstandardized coefficients, latent variances, covariances between latent variables, and the residual variance of PEQ.

```{r table 1: Model fit measures, echo=FALSE}
fit_index <- data.frame(Method = c("Matched-pair UPI", "RAPI", "2S-PA-Int"),
                        Unstandardized = c(".096", ".149", ".153"),
                        `$\\gamma_{PED}$` = c(".206", ".245", ".145"),
                        `$\\textit_{SE}$` = c(".018", ".017", ".019"),
                        `$\\textit_{p}$` = c("<.001", "<.001", "<.001"),
                        Unstandardized = c("-.515", "-.701", "-.851"),
                        `$\\gamma_{SelfE}$` = c("-.651", "-.559", "-.707"),
                        `$\\textit_{SE}$` = c(".015", ".015", ".017"),
                        `$\\textit_{p}$` = c("<.001", "<.001", "<.001"),
                        Unstandardized = c("-.041", "-.085", "-.06"),
                        `$\\gamma_{PED.SelfE}$` = c("-.067", "-.072", "-.05"),
                        `$\\textit_{SE}$` = c(".016", ".016", ".014"),
                        `$\\textit_{p}$` = c("<.001", "<.001", ".001"))
colnames(fit_index) <- c("Method", "$\\gamma_{1}$","$\\gamma_{1}''$", "$\\textit{SE}$", "$\\textit{p}$",
                         "$\\gamma_{2}$","$\\gamma_{2}''$", "$\\textit{SE}$", "$\\textit{p}$",
                         "$\\gamma_{3}$","$\\gamma_{3}''$", "$\\textit{SE}$", "$\\textit{p}$")

fit_index_table <- apa_table(fit_index,
                             escape = F,
                             caption = "Effects of Perceived Everyday Discrimination, Sefl-Esteem, and Their Interaction on Depression.",
                             align = c(rep("c", ncol(fit_index))),
                             col_spanners = list(`PED` = c(2, 5), `SelfE` = c(6, 9), `PED*SelfE` = c(10, 13)),
                             landscape = TRUE,
                             note = "$\\gamma$ = Unstandardized path coefficient; $\\gamma''$ = Standardized path coefficient; $\\textit{SE}$ = Standard error of standardized path coefficient; $\\textit{p}$ = p-value of standardized path coefficient.")

fit_index_table 
```

A summary of standardized estimates by three methods were listed in Table 1. In general, the structural path coefficients of PED, self-esteem, and their interaction effect on depression were similar across methods. It was found that PED had significantly positive effect on depression, meaning that participants who reported higher PED were scored higher on the PHQ-9 scale and more likely to have depressive symptoms. Self-esteem, however, had significantly negative effect on depression, and it implied that higher levels of self-esteem were associated with lower levels of depression. The interaction effect of self-esteem and PED on depression estimated by three methods were close to each other ($\gamma_{3}''$ = -.067, $\textit{SE}$ = .016, $\textit{p}$ < .001 for matched-pair UPI; $\gamma_{3}''$ = -.072, $\textit{SE}$ = .016, $\textit{p}$ < .001 for RAPI; $\gamma_{3}''$ = -.05, $\textit{SE}$ = .014, $\textit{p}$ = .001 for 2S-PA-Int), indicating that higher levels of self-esteem appeared to buffer or reduce the adverse impact of PED on depression. Overall, all the three methods were able to detect significant first-order and interaction effects as hypothesized in our theory. 

# Discussion

Testing for interaction effects is usually conducted in regression-based models with observed variables, which likely reduces statistical power to detect true effects due to ignored measurement error (Nakagawa, 2004; Lodder et al., 2019). Latent variables in the SEM framework can account for measurement error, and various latent interaction models that can model interaction effects among latent variables have been developed in the past 20 years. A theoretical model investigating how self-esteem altered the effect of PED on depression was tested using three latent interaction models of product indicator method in the current study, and we provided detailed step-by-step demonstrations of applying matched-pair UPI, RAPI, and 2S-PA-Int on the TAS2019 dataset from the PSID database. 

All of the approaches found a significant latent interaction effect of self-esteem, and the effect had similar magnitude across methods (i.e., .05 - .072), indicating that three methods were comparably acceptable to fit the empirical data under the hypothesized model. 2S-PA-Int produced the smallest magnitude of interaction effect (.05) with the smallest value of standard error (.014), whereas RAPI produced the largest magnitude (.072). This finding aligned with the simulation study comparing the three methods on a generated dataset, such that 2S-PA-Int tended to be more conservative in estimating the interaction effect, while RAPI and matched-pair UPI were more likely to overestimate the effect especially when sample size is small (Hsiao et al., 2021; Marsh et al., 2004). Besides, the standard error of the interaction effect for 2S-PA-Int was slightly smaller than that produced by RAPI (.016) and matched-pair UPI (.016), implying that 2S-PA-Int is more likely to estimate the interaction effect with more stability. Nevertheless, the differences on standardized coefficients and standard errors were not large and the three methods all showed good performance. 

A major limitation of this study is that most of the measures used in TAS2019 were Likert-scale data with a few response categories. Thus, strictly speaking, these measures should be regarded as categorical items with non-normal distributions. Given that the intricate details of implementing 2S-PA-Int on categorical data are under exploration, we treated the measures as continuous data and used uniform standard error of measurement to constrain the factor scores as SIs, which could result in biased estimates of interaction effect with inflated standard error. Besides, similar to 2S-PA-Int, the RAPI method was tested only on continuous data in simulation studies, and its performance on categorical indicators should be systematically assessed in varied conditions. The current acceptable results might not be convincing enough due to sampling variability. However, since the sample size of the TAS2019 dataset was large enough for empirical studies, the results seemed reasonable for 2S-PA-Int and RAPI. For future studies, a simulation study of comparing the three methods on categorical data can be conducted to systematically evaluate their performance under the violation of normal distributions. 


