@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2022},
  url = {https://www.R-project.org/},
}
@Manual{R-papaja,
  title = {{papaja}: {Prepare} reproducible {APA} journal articles with {R Markdown}},
  author = {Frederik Aust and Marius Barth},
  year = {2022},
  note = {R package version 0.1.1.9001},
  url = {https://github.com/crsh/papaja},
}
@Manual{R-tinylabels,
  title = {{tinylabels}: Lightweight Variable Labels},
  author = {Marius Barth},
  year = {2023},
  note = {R package version 0.2.4},
  url = {https://cran.r-project.org/package=tinylabels},
}
@Manual{R-dplyr,
  title = {dplyr: A Grammar of Data Manipulation},
  author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller and Davis Vaughan},
  year = {2023},
  note = {R package version 1.1.3},
  url = {https://CRAN.R-project.org/package=dplyr},
}
@Manual{R-tidyr,
  title = {tidyr: Tidy Messy Data},
  author = {Hadley Wickham and Davis Vaughan and Maximilian Girlich},
  year = {2024},
  note = {R package version 1.3.1},
  url = {https://CRAN.R-project.org/package=tidyr},
}
@article{alginaNoteEstimatingJoreskogYang2001,
  title = {A Note on Estimating the {{J{\"o}reskog-Yang}} Model for Latent Variable Interaction Using {{LISREL}} 8.3.},
  author = {Algina, James and Moulder, Bradley C.},
  year = {2001},
  journal = {Structural Equation Modeling},
  volume = {8},
  number = {1},
  pages = {40--52},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {1532-8007},
  doi = {10.1207/S15328007SEM0801_3},
  abstract = {D. A. Kenny and C. M. Judd (1984) developed a latent variable interaction model for observed variables centered around their population means. They estimated the model by using a covariance matrix calculated from sample-mean-centered variables and products of these variables. Subsequently, J{\"o}reskog and Yang (1996) identified the need to include intercepts for the measurement and structural equations and estimated the model by using a covariance matrix calculated from noncentered observed variables and products of these variables, and means of the observed variables and the products of noncentered variables. Evidence is presented that the J{\"o}reskog-Yang procedure for estimating the Kenny-Judd interaction model is subject to severe convergence problems when implemented in LISREL8.3 and means for the indicators of the latent exogenous variables are nonzero. An alternative procedure is presented that solves the convergence problem and provides consistent estimators of the parameters. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Estimation,Interaction Analysis (Statistics),Latent Variables,Models},
  file = {/Users/jimmy_z/Zotero/storage/W84UK2XX/2001-03013-003.html}
}

@article{bartlettStatisticalConceptionMental1937,
  title = {The {{Statistical Conception}} of {{Mental Factors}}},
  author = {Bartlett, M. S.},
  year = {1937},
  journal = {British Journal of Psychology. General Section},
  volume = {28},
  number = {1},
  pages = {97--104},
  issn = {2044-8295},
  doi = {10.1111/j.2044-8295.1937.tb00863.x},
  urldate = {2024-02-26},
  copyright = {1937 The British Psychological Society},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/WT9QMDW2/j.2044-8295.1937.tb00863.html}
}

@article{bollenLatentVariablesPsychology2002a,
  title = {Latent Variables in Psychology and the Social Sciences},
  author = {Bollen, Kenneth A.},
  year = {2002},
  journal = {Annual Review of Psychology},
  volume = {53},
  number = {1},
  pages = {605--634},
  publisher = {{Annual Reviews}},
  address = {{US}},
  issn = {1545-2085},
  doi = {10.1146/annurev.psych.53.100901.135239},
  abstract = {The paper discusses the use of latent variables in psychology and social science research. Local independence, expected value true scores, and nondeterministic functions of observed variables are three types of definitions for latent variables. These definitions are reviewed and an alternative "sample realizations" definition is presented. Another section briefly describes identification, latent variable indeterminancy, and other properties common to models with latent variables. The paper then reviews the role of latent variables in multiple regression, probit and logistic regression, factor analysis, latent curve models, item response theory, latent class analysis, and structural equation models. Though these application areas are diverse, the paper highlights the similarities as well as the differences in the manner in which the latent variables are defined and used. It concludes with an evaluation of the different definitions of latent variables and their properties. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Latent Variables,Methodology,Psychology,Social Sciences,Statistical Analysis,Statistical Variables,Theories},
  file = {/Users/jimmy_z/Zotero/storage/HN2BCC4F/2001-09759-022.html}
}

@book{bollenStructuralEquationsLatent1989d,
  title = {Structural Equations with Latent Variables},
  author = {Bollen, Kenneth A.},
  year = {1989},
  series = {Structural Equations with Latent Variables},
  pages = {xiv, 514},
  publisher = {{John Wiley \& Sons}},
  address = {{Oxford, England}},
  doi = {10.1002/9781118619179},
  abstract = {"Structural Equations with Latent Variables" is a comprehensive treatment of the general structural equation system better known as the LISREL model. The book serves three purposes. First, it demonstrates the generality of this model. Rather than treating path analysis, recursive and nonrecursive models, classical econometrics, and confirmatory factor analysis as unique, they are treated as special cases of a common model. The second purpose is to emphasize the application of these techniques. Empirical examples appear throughout. Several chapters contain some of the LISREL or EQS programs the author used to obtain the results for the empirical examples. Finally, the book explores the crucial role played by substantive expertise in most stages of the modeling process.  "Structural Equations with Latent Variables" fills the gap existing in the treatment of this subject between introductory texts and specialized papers. It provides social scientists, market researchers, applied statisticians, other analysts, and graduate students with a thorough examination of LISREL/structural equation models. At the same time it presents new material on measurement reliability and validity, overall fit indices, model identification, and other topics. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  isbn = {978-0-471-01171-2},
  keywords = {Computer Software,Factor Analysis,Factor Structure,Latent Variables,Linear Regression,Statistical Measurement,Statistical Variables,Statistics},
  file = {/Users/jimmy_z/Zotero/storage/ANLFPFZA/1989-97716-000.html}
}

@book{bollenTestingStructuralEquation1993,
  title = {Testing Structural Equation Models},
  editor = {Bollen, Kenneth A. and Long, J. Scott},
  year = {1993},
  series = {Testing Structural Equation Models},
  pages = {320},
  publisher = {{Sage Publications, Inc}},
  address = {{Thousand Oaks, CA, US}},
  abstract = {should be used as a text in graduate-level courses on sturctural equation models to augment the standard textbooks (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-8039-4506-7 978-0-8039-4507-4},
  keywords = {Goodness of Fit,Mathematical Modeling},
  file = {/Users/jimmy_z/Zotero/storage/FVJUE4BJ/1993-97481-000.html}
}

@book{brownConfirmatoryFactorAnalysis2015,
  title = {Confirmatory Factor Analysis for Applied Research, 2nd Ed},
  author = {Brown, Timothy A.},
  year = {2015},
  series = {Confirmatory Factor Analysis for Applied Research, 2nd Ed},
  pages = {xvii, 462},
  publisher = {{The Guilford Press}},
  address = {{New York, NY, US}},
  abstract = {With its emphasis on practical and conceptual aspects, rather than mathematics or formulas, This accessible book has established itself as the go-to resource on confirmatory factor analysis (CFA). Detailed, worked-through examples drawn from psychology, management, and sociology studies illustrate the procedures, pitfalls, and extensions of CFA methodology. The text shows how to formulate, program, and interpret CFA models using popular latent variable software packages (LISREL, Mplus, EQS, SAS/CALIS); understand the similarities and differences between CFA and exploratory factor analysis (EFA); and report results from a CFA study. It is filled with useful advice and tables that outline the procedures. The companion website (www.guilford.com/brown3-materials) offers data and program syntax files for most of the research examples, as well as links to CFA-related resources. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  isbn = {978-1-4625-1779-4 978-1-4625-1536-3 978-1-4625-1781-7},
  keywords = {Applied Psychology,Computer Software,Confirmatory Factor Analysis,Factor Analysis,Factor Structure,Latent Variables,Mathematical Modeling,Methodology},
  file = {/Users/jimmy_z/Zotero/storage/C9UNQ9C3/2015-10560-000.html}
}

@book{byrneStructuralEquationModeling2016,
  title = {Structural {{Equation Modeling With AMOS}}: {{Basic Concepts}}, {{Applications}}, and {{Programming}}, {{Third Edition}}},
  shorttitle = {Structural {{Equation Modeling With AMOS}}},
  author = {Byrne, Barbara M.},
  year = {2016},
  month = jun,
  edition = {3},
  publisher = {{Routledge}},
  address = {{New York}},
  doi = {10.4324/9781315757421},
  abstract = {This bestselling text provides a practical guide to structural equation modeling (SEM) using the Amos Graphical approach. Using clear, everyday language, the text is ideal for those with little to no exposure to either SEM or Amos. The author reviews SEM applications based on actual data taken from her own research. Each chapter "walks" readers through the steps involved (specification, estimation, evaluation, and post hoc modification) in testing a variety of SEM models. Accompanying each application is: an explanation of the issues addressed and a schematic presentation of hypothesized model structure; Amos　 input and output with interpretations; use of the Amos toolbar icons and pull-down menus; and data upon which the model application was based, together with updated references pertinent to the SEM model　 tested. Thoroughly updated throughout, the new edition features: All new screen shots featuring Amos Version 23.　　  Descriptions and illustrations of Amos' new Tables View format which enables the specification of a structural model in spreadsheet form.　　　　  Key concepts and/or techniques that introduce each chapter.  Alternative approaches to model analyses when enabled by Amos thereby allowing users to determine the method best suited to their data.　  Provides analysis of the same model based on continuous and categorical data (Ch. 5) thereby enabling readers to observe two ways of specifying and testing the same model as well as compare results.  All applications based on the Amos graphical mode interface accompanied by more "how to" coverage of graphical techniques unique to Amos. More explanation of key procedures and analyses that address questions posed by readers  All application data files are available at www.routledge.com/9781138797031. The two introductory chapters in Section 1 review the fundamental concepts of SEM methodology and a general overview of the Amos program. Section 2 provides single-group analyses applications including two first-order confirmatory factor analytic (CFA) models, one second-order CFA model, and one full latent variable model. Section 3 presents multiple-group analyses applications with two rooted in the analysis of covariance structures and one in the analysis of mean and covariance structures. Two models that are increasingly popular with SEM practitioners, construct validity and testing change over time using the latent growth curve, are presented in Section 4. The book concludes with a review of the use of bootstrapping to address non-normal data and a review of missing (or incomplete) data in Section 5.  An ideal supplement for graduate level courses in psychology, education, business, and social and health sciences that cover the fundamentals of SEM with a focus on Amos, this practical text continues to be a favorite of both researchers and practitioners. A prerequisite of basic statistics through regression analysis is recommended but no exposure to either SEM or Amos is required.},
  isbn = {978-1-315-75742-1}
}

@article{cartePURSUITMODERATIONNINE2003a,
  title = {{{In pursuit of moderation}}: {{Nine common errors and thir solutions}}},
  shorttitle = {{{In pursuit of moderation}}},
  author = {Carte, Traci and Russell, Craig J.},
  year = {2003},
  month = sep,
  urldate = {2024-02-26},
  abstract = {One result of the increasing sophistication and complexity of MIS theory and research is the number of studies hypothesizing and testing for moderation effects. A review of the MIS and broader management literatures suggests researchers investigating moderated relationships often commit one or more errors falling into three broad categories: inappropriate use or interpretation of statistics, misalignment of research design with phenomena of interest, and measurement or scaling issues. Examples of nine common errors are presented. Commission of these errors is expected to yield literatures characterized by mixed results at best, and thoroughly erroneous results at worse. Procedures representing examples of best practice and reporting guidelines are provided to help MIS investigators avoid or minimize these errors.},
  langid = {english},
  annotation = {Accepted: 2016-10-10T19:29:12Z},
  file = {/Users/jimmy_z/Zotero/storage/F5G9ZC45/Carte and Russell - 2003 - IN PURSUIT OF MODERATION NINE COMMON ERRORS AND T.pdf}
}

@article{chamEstimatingLatentVariable2012a,
  title = {Estimating {{Latent Variable Interactions With Non-Normal Observed Data}}: {{A Comparison}} of {{Four Approaches}}},
  shorttitle = {Estimating {{Latent Variable Interactions With Non-Normal Observed Data}}},
  author = {Cham, Heining and West, Stephen G. and Ma, Yue and Aiken, Leona S.},
  year = {2012},
  journal = {Multivariate Behav Res},
  volume = {47},
  number = {6},
  pages = {840--876},
  issn = {0027-3171},
  doi = {10.1080/00273171.2012.732901},
  urldate = {2024-02-26},
  abstract = {A Monte Carlo simulation was conducted to investigate the robustness of four latent variable interaction modeling approaches (Constrained Product Indicator [CPI], Generalized Appended Product Indicator [GAPI], Unconstrained Product Indicator [UPI], and Latent Moderated Structural Equations [LMS]) under high degrees of non-normality of the observed exogenous variables. Results showed that the CPI and LMS approaches yielded biased estimates of the interaction effect when the exogenous variables were highly non-normal. When the violation of non-normality was not severe (normal; symmetric with excess kurtosis {$<$} 1), the LMS approach yielded the most efficient estimates of the latent interaction effect with the highest statistical power. In highly non-normal conditions, the GAPI and UPI approaches with ML estimation yielded unbiased latent interaction effect estimates, with acceptable actual Type-I error rates for both the Wald and likelihood ratio tests of interaction effect at N {$\geq$} 500. An empirical example illustrated the use of the four approaches in testing a latent variable interaction between academic self-efficacy and positive family role models in the prediction of academic performance.},
  pmcid = {PMC3583564},
  pmid = {23457417},
  file = {/Users/jimmy_z/Zotero/storage/3KHIFGBY/Cham et al. - 2012 - Estimating Latent Variable Interactions With Non-N.pdf}
}

@article{chinPartialLeastSquares2003,
  title = {A {{Partial Least Squares Latent Variable Modeling Approach}} for {{Measuring Interaction Effects}}: {{Results}} from a {{Monte Carlo Simulation Study}} and an {{Electronic-Mail Emotion}}/{{Adoption Study}}},
  shorttitle = {A {{Partial Least Squares Latent Variable Modeling Approach}} for {{Measuring Interaction Effects}}},
  author = {Chin, Wynne W. and Marcolin, Barbara L. and Newsted, Peter R.},
  year = {2003},
  journal = {Information Systems Research},
  volume = {14},
  number = {2},
  pages = {189--217},
  publisher = {{Institute for Operations Research \& the Management Sciences (INFORMS)}},
  address = {{US}},
  issn = {1526-5536},
  doi = {10.1287/isre.14.2.189.16018},
  abstract = {The ability to detect and accurately estimate the strength of interaction effects are critical issues that are fundamental to social science research in general and information systems (IS) research in particular. Within the IS discipline, a significant percentage of research has been devoted to examining the conditions and contexts under which relationships may vary, often under the general umbrella of contingency theory. In our survey of IS studies, the majority failed to either detect or provide an estimate of the effect size. In cases where effect sizes are estimated, the numbers are generally small. These data have led some researchers to question both the usefulness of contingency theory and the need to detect interaction effects. This paper addresses this issue by providing a new latent variable modeling approach that can give more accurate estimates of interaction effects by accounting for the measurement error that attenuates the estimated relationships. The capacity of this approach at recovering true effects in comparison to summated regression is demonstrated in a Monte Carlo study that creates a simulated data set in which the underlying true effects are known. Analysis of a second, empirical data set is included to demonstrate the technique's use within IS theory. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Computer Attitudes,Computer Mediated Communication,Emotional States,Error of Measurement,Information Theory,Latent Variables,Simulation},
  file = {/Users/jimmy_z/Zotero/storage/A7DVZM7T/2003-99380-004.html}
}

@book{cohenAppliedMultipleRegression2003,
  title = {Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed},
  author = {Cohen, Jacob and Cohen, Patricia and West, Stephen G. and Aiken, Leona S.},
  year = {2003},
  series = {Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed},
  pages = {xxviii, 703},
  publisher = {{Lawrence Erlbaum Associates Publishers}},
  address = {{Mahwah, NJ, US}},
  abstract = {Multiple regression correlation (MRC) analysis is a highly general and therefore very flexible data analytic system. Basic MRC may be used whenever a quantitative variable, the dependent variable, is to be studied as a function of, or in relationship of, any factors of interest, the independent variables. This book strongly emphasizes the critical role of theory in planning MRC analyses, and was written to serve as a textbook and manual in the application of the MRC system for data analysis by students and practitioners in diverse areas in inquiry in the behavioral sciences, health sciences, education, and business. Its orientation is nonmathematical, applied, and data-analytic. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-8058-2223-6},
  keywords = {Analysis of Variance,Behavioral Sciences,Multiple Regression,Statistical Correlation,Statistical Variables},
  file = {/Users/jimmy_z/Zotero/storage/75WNQJ9W/2002-18109-000.html}
}

@article{collinsComparisonInclusiveRestrictive2001,
  title = {A Comparison of Inclusive and Restrictive Strategies in Modern Missing Data Procedures},
  author = {Collins, L. M. and Schafer, J. L. and Kam, C. M.},
  year = {2001},
  month = dec,
  journal = {Psychol Methods},
  volume = {6},
  number = {4},
  pages = {330--351},
  issn = {1082-989X},
  abstract = {Two classes of modern missing data procedures, maximum likelihood (ML) and multiple imputation (MI), tend to yield similar results when implemented in comparable ways. In either approach, it is possible to include auxiliary variables solely for the purpose of improving the missing data procedure. A simulation was presented to assess the potential costs and benefits of a restrictive strategy, which makes minimal use of auxiliary variables, versus an inclusive strategy, which makes liberal use of such variables. The simulation showed that the inclusive strategy is to be greatly preferred. With an inclusive strategy not only is there a reduced chance of inadvertently omitting an important cause of missingness, there is also the possibility of noticeable gains in terms of increased efficiency and reduced bias, with only minor costs. As implemented in currently available software, the ML approach tends to encourage the use of a restrictive strategy, whereas the MI approach makes it relatively simple to use an inclusive strategy.},
  langid = {english},
  pmid = {11778676},
  keywords = {Confidence Intervals,Data Collection,Humans,Likelihood Functions,Models Statistical,Psychological Tests,Psychology Experimental,Psychometrics}
}

@book{crainiceanuMeasurementErrorNonlinear2006,
  title = {Measurement {{Error}} in {{Nonlinear Models}}: {{A Modern Perspective}}, {{Second Edition}}},
  shorttitle = {Measurement {{Error}} in {{Nonlinear Models}}},
  author = {Crainiceanu, David Ruppert, Leonard A. Stefanski, Ciprian M., Raymond J. Carroll},
  year = {2006},
  month = jun,
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  address = {{New York}},
  doi = {10.1201/9781420010138},
  abstract = {It's been over a decade since the first edition of Measurement Error in Nonlinear Models splashed onto the scene, and research in the field has certainly not cooled in the interim. In fact, quite the opposite has occurred. As a result, Measurement Error in Nonlinear Models: A Modern Perspective, Second Edition has been revamped and ex},
  isbn = {978-0-429-13963-5}
}

@article{cronbachCoefficientAlphaInternal1951,
  title = {Coefficient Alpha and the Internal Structure of Tests},
  author = {Cronbach, Lee J.},
  year = {1951},
  month = sep,
  journal = {Psychometrika},
  volume = {16},
  number = {3},
  pages = {297--334},
  issn = {1860-0980},
  doi = {10.1007/BF02310555},
  urldate = {2024-02-26},
  abstract = {A general formula ({$\alpha$}) of which a special case is the Kuder-Richardson coefficient of equivalence is shown to be the mean of all split-half coefficients resulting from different splittings of a test. {$\alpha$} is therefore an estimate of the correlation between two random samples of items from a universe of items like those in the test. {$\alpha$} is found to be an appropriate index of equivalence and, except for very short tests, of the first-factor concentration in the test. Tests divisible into distinct subtests should be so divided before using the formula. The index\$\${\textbackslash}bar r\_\{ij\} \$\$, derived from {$\alpha$}, is shown to be an index of inter-item homogeneity. Comparison is made to the Guttman and Loevinger approaches. Parallel split coefficients are shown to be unnecessary for tests of common types. In designing tests, maximum interpretability of scores is obtained by increasing the first-factor concentration in any separately-scored subtest and avoiding substantial group-factor clusters within a subtest. Scalability is not a requisite.},
  langid = {english},
  keywords = {Common Type,Internal Structure,Public Policy,Random Sample,Statistical Theory},
  file = {/Users/jimmy_z/Zotero/storage/I7BHM3QH/Cronbach - 1951 - Coefficient alpha and the internal structure of te.pdf}
}

@article{cunninghamModerationSportManagement2019a,
  title = {Moderation in {{Sport Management Research}}: {{Room}} for {{Growth}}},
  shorttitle = {Moderation in {{Sport Management Research}}},
  author = {Cunningham, George B. and Ahn, Na Young},
  year = {2019},
  journal = {Measurement in Physical Education and Exercise Science},
  volume = {23},
  number = {4},
  pages = {301--313},
  publisher = {{Routledge}},
  issn = {1091-367X},
  doi = {10.1080/1091367X.2018.1472095},
  urldate = {2024-02-26},
  abstract = {Moderators are variables that affect the relationship between a predictor and outcome. They help to clarify otherwise ambiguous patterns of results, extend theory, and signal the growth of a field. Given the importance of moderators, the authors offer an overview of methodological and statistical considerations for testing moderation and then examine sport management scholars' use of moderation in their research. A content analysis of "European Sport Management Quarterly," "Journal of Sport Management," and "Sport Management Review" shows that tests of moderation have not followed the growth in scholarship in the field. Further analyses showed (a) analysis of variance was the most popular analytical tool employed; (b) one in six tests of moderation were conducted incorrectly; and (c) 13\% of tests for moderation were conducted absent specific hypotheses or research questions. The authors offer implications for sport management researchers.},
  langid = {english},
  keywords = {Athletics,Regression (Statistics),Research,Research Methodology,Statistical Analysis,Structural Equation Models},
  annotation = {ERIC Number: EJ1233906},
  file = {/Users/jimmy_z/Zotero/storage/WKWKRLRL/eric-ed-gov.libproxy1.usc.edu.html}
}

@article{daszykowskiRobustStatisticsData2007,
  title = {Robust Statistics in Data Analysis {\textemdash} {{A}} Review},
  author = {Daszykowski, M. and Kaczmarek, K. and Vander Heyden, Y. and Walczak, B.},
  year = {2007},
  month = feb,
  journal = {Chemometrics and Intelligent Laboratory Systems},
  volume = {85},
  number = {2},
  pages = {203--219},
  issn = {01697439},
  doi = {10.1016/j.chemolab.2006.06.016},
  urldate = {2024-02-26},
  abstract = {Presence of outliers in chemical data affects all least squares models, which are extensively used in chemometrics for data exploration and modeling. Therefore, more and more attention is paid to the so-called robust models and robust statistics that aim to construct models and estimates describing well data majority. Moreover, construction of robust models allows identifying outlying observations. The outliers identification is not only essential for a proper modeling but also for understanding the reasons for unique character of the outlying sample.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/KLYFKJU3/Daszykowski et al. - 2007 - Robust statistics in data analysis — A review.pdf}
}

@article{devliegerHypothesisTestingUsing2016,
  title = {Hypothesis {{Testing Using Factor Score Regression}}},
  author = {Devlieger, Ines and Mayer, Axel and Rosseel, Yves},
  year = {2016},
  month = oct,
  journal = {Educ Psychol Meas},
  volume = {76},
  number = {5},
  pages = {741--770},
  issn = {0013-1644},
  doi = {10.1177/0013164415607618},
  urldate = {2024-02-26},
  abstract = {In this article, an overview is given of four methods to perform factor score regression (FSR), namely regression FSR, Bartlett FSR, the bias avoiding method of Skrondal and Laake, and the bias correcting method of Croon. The bias correcting method is extended to include a reliable standard error. The four methods are compared with each other and with structural equation modeling (SEM) by using analytic calculations and two Monte Carlo simulation studies to examine their finite sample characteristics. Several performance criteria are used, such as the bias using the unstandardized and standardized parameterization, efficiency, mean square error, standard error bias, type I error rate, and power. The results show that the bias correcting method, with the newly developed standard error, is the only suitable alternative for SEM. While it has a higher standard error bias than SEM, it has a comparable bias, efficiency, mean square error, power, and type I error rate.},
  pmcid = {PMC5965529},
  pmid = {29795886},
  file = {/Users/jimmy_z/Zotero/storage/64UYAX6S/Devlieger et al. - 2016 - Hypothesis Testing Using Factor Score Regression.pdf}
}

@article{estabrookComparisonFactorScore2013,
  title = {A {{Comparison}} of {{Factor Score Estimation Methods}} in the {{Presence}} of {{Missing Data}}: {{Reliability}} and an {{Application}} to {{Nicotine Dependence}}},
  shorttitle = {A {{Comparison}} of {{Factor Score Estimation Methods}} in the {{Presence}} of {{Missing Data}}},
  author = {Estabrook, Ryne and Neale, Michael},
  year = {2013},
  month = jan,
  journal = {Multivariate Behav Res},
  volume = {48},
  number = {1},
  pages = {1--27},
  issn = {1532-7906},
  doi = {10.1080/00273171.2012.730072},
  abstract = {Factor score estimation is a controversial topic in psychometrics, and the estimation of factor scores from exploratory factor models has historically received a great deal of attention. However, both confirmatory factor models and the existence of missing data have generally been ignored in this debate. This article presents a simulation study that compares the reliability of sum scores, regression-based and expected posterior methods for factor score estimation for confirmatory factor models in the presence of missing data. Although all methods perform reasonably well with complete data, expected posterior-weighted (full) maximum likelihood methods are significantly more reliable than sum scores and regression estimators in the presence of missing data. Factor score reliability for complete data can be predicted by Guttman's 1955 formula for factor communality. Furthermore, factor score reliability for incomplete data can be reasonably approximated by communality raised to the [Formula: see text] power. An empirical demonstration shows that the full maximum likelihood method best preserves the relationship between nicotine dependence and a genetic predictor under missing data. Implications and recommendations for applied research are discussed.},
  langid = {english},
  pmcid = {PMC3773873},
  pmid = {24049215},
  file = {/Users/jimmy_z/Zotero/storage/SMV8VXQS/Estabrook and Neale - 2013 - A Comparison of Factor Score Estimation Methods in.pdf}
}

@article{foldnesChoiceProductIndicators2014,
  title = {The Choice of Product Indicators in Latent Variable Interaction Models: {{Post}} Hoc Analyses},
  shorttitle = {The Choice of Product Indicators in Latent Variable Interaction Models},
  author = {Foldnes, Nj{\aa}l and Hagtvet, Knut Arne},
  year = {2014},
  journal = {Psychological Methods},
  volume = {19},
  number = {3},
  pages = {444--457},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1463},
  doi = {10.1037/a0035728},
  abstract = {The unconstrained product indicator (PI) approach is a simple and popular approach for modeling nonlinear effects among latent variables. This approach leaves the practitioner to choose the PIs to be included in the model, introducing arbitrariness into the modeling. In contrast to previous Monte Carlo studies, we evaluated the PI approach by 3 post hoc analyses applied to a real-world case adopted from a research effort in social psychology. The measurement design applied 3 and 4 indicators for the 2 latent 1st-order variables, leaving the researcher with a choice among more than 4,000 possible PI configurations. Sixty so-called matched-pair configurations that have been recommended in previous literature are of special interest. In the 1st post hoc analysis we estimated the interaction effect for all PI configurations, keeping the real-world sample fixed. The estimated interaction effect was substantially affected by the choice of PIs, also across matched-pair configurations. Subsequently, a post hoc Monte Carlo study was conducted, with varying sample sizes and data distributions. Convergence, bias, Type I error and power of the interaction test were investigated for each matched-pair configuration and the all-pairs configuration. Variation in estimates across matched-pair configurations for a typical sample was substantial. The choice of specific configuration significantly affected convergence and the interaction test's outcome. The all-pairs configuration performed overall better than the matched-pair configurations. A further advantage of the all-pairs over the matched-pairs approach is its unambiguity. The final study evaluates the all-pairs configuration for small sample sizes and compares it to the non-PI approach of latent moderated structural equations. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Latent Variables,Mathematical Modeling,Statistical Analysis,Statistical Estimation,Structural Equation Modeling}
}

@article{hancockReliabilityParadoxAssessing2011,
  title = {The {{Reliability Paradox}} in {{Assessing Structural Relations Within Covariance Structure Models}}},
  author = {Hancock, Gregory R. and Mueller, Ralph O.},
  year = {2011},
  month = apr,
  journal = {Educational and Psychological Measurement},
  volume = {71},
  number = {2},
  pages = {306--324},
  publisher = {{SAGE Publications Inc}},
  issn = {0013-1644},
  doi = {10.1177/0013164410384856},
  urldate = {2024-02-26},
  abstract = {A two-step process is commonly used to evaluate data{\textendash}model fit of latent variable path models, the first step addressing the measurement portion of the model and the second addressing the structural portion of the model. Unfortunately, even if the fit of the measurement portion of the model is perfect, the ability to assess the fit within the structural portion is affected by the quality of the factor{\textendash}variable relations within the measurement model. The result is that models with poorer quality measurement appear to have better data{\textendash}model fit, whereas models with better quality measurement appear to have worse data{\textendash}model fit. The current article illustrates this phenomenon across different classes of fit indices, discusses related structural assessment problems resulting from issues of measurement quality, and endorses a supplemental modeling step evaluating the structural portion of the model in isolation from the measurement model.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/AXEYP3RI/Hancock and Mueller - 2011 - The Reliability Paradox in Assessing Structural Re.pdf}
}

@article{harwellStrategyUsingBias2019,
  title = {A {{Strategy}} for {{Using Bias}} and {{RMSE}} as {{Outcomes}} in {{Monte Carlo Studies}} in {{Statistics}}},
  author = {Harwell, Michael},
  year = {2019},
  month = mar,
  journal = {J. Mod. Appl. Stat. Methods},
  volume = {17},
  number = {2},
  pages = {jmasm.eP2938},
  issn = {1538-9472},
  doi = {10.22237/jmasm/1551907966},
  urldate = {2024-02-26},
  abstract = {To help ensure important patterns of bias and accuracy are detected in Monte Carlo studies in statistics this paper proposes conditioning bias and root mean square error (RMSE) measures on estimated Type I and Type II error rates. A small Monte Carlo study is used to illustrate this argument.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/LWHF4D4L/Harwell - 2019 - A Strategy for Using Bias and RMSE as Outcomes in .pdf}
}

@incollection{hershbergerFactorScoreEstimation2005,
  title = {Factor {{Score Estimation}}},
  booktitle = {Encyclopedia of {{Statistics}} in {{Behavioral Science}}},
  author = {Hershberger, Scott L.},
  year = {2005},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/0470013192.bsa726},
  urldate = {2024-02-26},
  abstract = {Factors scores are measures of principal components or common factors. Under the principal components model, the factor scores are uniquely determined; under the common factor model, they are not. In the latter situation, the factor scores are indeterminate, potentially having an infinite number of solution sets, and thus their true values can only be estimated. Three methods of factor score estimation are discussed: (a) regression, (b) Bartlett's method, and (c) Anderson and Rubin's method. Although the properties and values of the factor score estimates produced by the three methods differ, the estimates are in general highly correlated.},
  copyright = {Copyright {\textcopyright} 2005 John Wiley \& Sons, Ltd. All rights reserved.},
  isbn = {978-0-470-01319-9},
  langid = {english},
  keywords = {common factor model,factor analysis,latent variables,principal components model,underidentification},
  file = {/Users/jimmy_z/Zotero/storage/Y27SDQB3/0470013192.html}
}

@article{hooglandRobustnessStudiesCovariance1998,
  title = {Robustness {{Studies}} in {{Covariance Structure Modeling}}: {{An Overview}} and a {{Meta-Analysis}}},
  shorttitle = {Robustness {{Studies}} in {{Covariance Structure Modeling}}},
  author = {HOOGLAND, JEFFREY J. and BOOMSMA, {\relax ANNE}},
  year = {1998},
  month = feb,
  journal = {Sociological Methods \& Research},
  volume = {26},
  number = {3},
  pages = {329--367},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/0049124198026003003},
  urldate = {2024-02-26},
  abstract = {In covariance structure modeling, several estimation methods are available. The robustness of an estimator against specific violations of assumptions can be determined empirically by means of a Monte Carlo study. Many such studies in covariance structure analysis have been published, but the conclusions frequently seem to contradict each other. An overview of robustness studies in covariance structure analysis is given, and an attempt is made to generalize findings. Robustness studies are described and distinguished from each other systematically by means of certain characteristics. These characteristics serve as explanatory variables in a meta-analysis concerning the behavior of parameter estimators, standard error estimators, and goodness-of-fit statistics when the model is correctly specified.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/PEDNRYH9/HOOGLAND and BOOMSMA - 1998 - Robustness Studies in Covariance Structure Modelin.pdf}
}

@article{hsiaoEvaluationTwoMethods2018a,
  title = {Evaluation of {{Two Methods}} for {{Modeling Measurement Errors When Testing Interaction Effects With Observed Composite Scores}}},
  author = {Hsiao, Yu-Yu and Kwok, Oi-Man and Lai, Mark H. C.},
  year = {2018},
  month = apr,
  journal = {Educ Psychol Meas},
  volume = {78},
  number = {2},
  pages = {181--202},
  issn = {0013-1644},
  doi = {10.1177/0013164416679877},
  urldate = {2024-02-26},
  abstract = {Path models with observed composites based on multiple items (e.g., mean or sum score of the items) are commonly used to test interaction effects. Under this practice, researchers generally assume that the observed composites are measured without errors. In this study, we reviewed and evaluated two alternative methods within the structural equation modeling (SEM) framework, namely, the reliability-adjusted product indicator (RAPI) method and the latent moderated structural equations (LMS) method, which can both flexibly take into account measurement errors. Results showed that both these methods generally produced unbiased estimates of the interaction effects. On the other hand, the path model{\textemdash}without considering measurement errors{\textemdash}led to substantial bias and a low confidence interval coverage rate of nonzero interaction effects. Other findings and implications for future studies are discussed.},
  pmcid = {PMC5965658},
  pmid = {29795952},
  file = {/Users/jimmy_z/Zotero/storage/5NRJL8JY/Hsiao et al. - 2018 - Evaluation of Two Methods for Modeling Measurement.pdf}
}

@article{hsiaoModelingMeasurementErrors2021,
  title = {Modeling {{Measurement Errors}} of the {{Exogenous Composites From Congeneric Measures}} in {{Interaction Models}}},
  author = {Hsiao, Yu-Yu and Kwok, Oi-Man and Lai, Mark H. C.},
  year = {2021},
  journal = {Struct Equ Modeling},
  volume = {28},
  number = {2},
  pages = {250--260},
  issn = {1070-5511},
  doi = {10.1080/10705511.2020.1782206},
  urldate = {2024-02-26},
  abstract = {We investigated the performance of two single indicator methods: latent moderated structural equation (LMS) and reliability-adjusted product indicator (RAPI) methods, on testing interaction effects with congeneric measures, which vary in factor loadings and error variances under a common factor. Additionally, in the simulation study, we compared the performance of four reliability estimates (Cronbach's alpha, omega composite, Coefficient H, and greatest lower bound [GLB]) to adjust for the exogenous composites' measurement errors. Results from the study showed that: while estimating interaction effects with exogenous composites from congeneric measures, the four reliability estimates performed comparably well. Recommendations on the choice of reliability estimates between the LMS and the RAPI methods under different sample sizes and population reliability conditions are further discussed.},
  pmcid = {PMC8259412},
  pmid = {34239281},
  file = {/Users/jimmy_z/Zotero/storage/TY56HZEA/Hsiao et al. - 2021 - Modeling Measurement Errors of the Exogenous Compo.pdf}
}

@article{jackmanEstimatingLatentVariable2011a,
  title = {Estimating {{Latent Variable Interactions With}} the {{Unconstrained Approach}}: {{A Comparison}} of {{Methods}} to {{Form Product Indicators}} for {{Large}}, {{Unequal Numbers}} of {{Items}}},
  shorttitle = {Estimating {{Latent Variable Interactions With}} the {{Unconstrained Approach}}},
  author = {Jackman, Grace-Anne and Leite, Walter and Cochrane, David},
  year = {2011},
  month = apr,
  journal = {Structural Equation Modeling},
  volume = {18},
  pages = {274--288},
  doi = {10.1080/10705511.2011.557342},
  abstract = {This Monte Carlo simulation study investigated methods of forming product indicators for the unconstrained approach for latent variable interaction estimation when the exogenous factors are measured by large and unequal numbers of indicators. Product indicators were created based on multiplying parcels of the larger scale by indicators of the smaller scale, multiplying the three most reliable indicators of each scale matched by reliability, and matching items by reliability to create as many product indicators as the number of indicators of the smallest scale. The unconstrained approach was compared with the latent moderated structural equations (LMS) approach. All methods considered provided unbiased parameter estimates. Unbiased standard errors were obtained in all conditions with the LMS approach and when the sample size was large with the unconstrained approach. Power levels to test the latent interaction and Type I error rates were similar for all methods but slightly better for the LMS approach.}
}

@article{joreskogStatisticalAnalysisSets1971,
  title = {Statistical Analysis of Sets of Congeneric Tests},
  author = {J{\"o}reskog, K. G.},
  year = {1971},
  month = jun,
  journal = {Psychometrika},
  volume = {36},
  number = {2},
  pages = {109--133},
  issn = {1860-0980},
  doi = {10.1007/BF02291393},
  urldate = {2024-02-26},
  abstract = {Various models for sets of congeneric tests are considered, including models appropriate for the analysis of multitrait-multimethod data. All models are illustrated with real data. The special cases when two or more tests within a set are tau-equivalent or parallel are also considered. All data analyses are done within the framework of a general model by J{\"o}reskog [1970].},
  langid = {english},
  keywords = {Data Analysis,General Model,Public Policy,Real Data,Statistical Theory}
}

@inproceedings{Jreskog1996NonlinearSE,
  title = {Nonlinear Structural Equation Models: {{The Kenny-Judd}} Model with {{Interaction}} Effects},
  author = {J{\"o}reskog, Karl G. and Yang, Fan},
  year = {1996}
}

@article{kennyEstimatingNonlinearInteractive1984a,
  title = {Estimating the Nonlinear and Interactive Effects of Latent Variables},
  author = {Kenny, David A. and Judd, Charles M.},
  year = {1984},
  journal = {Psychological Bulletin},
  volume = {96},
  number = {1},
  pages = {201--210},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1455},
  doi = {10.1037/0033-2909.96.1.201},
  abstract = {Describes a procedure that enables researchers to estimate nonlinear and interactive effects of latent variables in structural equation models. Given that the latent variables are normally distributed, the parameters of such models can be estimated. To do this, products of the measured variables are used as indicators of latent product variables. Estimation must be done using a procedure that allows nonlinear constraints on parameters. The procedure is demonstrated in 3 examples. The 1st 2 examples use artificial data with known parameter values. These parameters are successfully recovered by the procedure. The final complex example uses national election survey data. (14 ref) (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Estimation,Latent Variables,Mathematical Modeling},
  file = {/Users/jimmy_z/Zotero/storage/IAY5ZR2M/1984-27738-001.html}
}

@book{klinePrinciplesPracticeStructural2016,
  title = {Principles and Practice of Structural Equation Modeling, 4th Ed},
  author = {Kline, Rex B.},
  year = {2016},
  series = {Principles and Practice of Structural Equation Modeling, 4th Ed},
  pages = {xvii, 534},
  publisher = {{Guilford Press}},
  address = {{New York, NY, US}},
  abstract = {Rex Kline has assembled a fourth edition that retains all the wonderful features of his best selling earlier editions, and he seamlessly integrates recent advances in structural equation modeling (SEM). Rex is a scholar of SEM and has a special gift{\textemdash}of being able to communicate complex statistical concepts in language that all readers can grasp. The accessible style of writing and the many pedagogical features of the book (e.g., chapter-end annotated reading lists, exercises with answers) make it a "must have" for any user of SEM. It is a resource that keeps improving and expanding with each new edition and is the resource I recommend first on this subject{\textemdash}whether the question comes from a beginner or an experienced user. As a scholar of modern statistical practice and techniques. Rex has studied the developments and advances in the world of SEM generally, and he has covered "hot" topics, such as Pearl's structural causal modeling. His coverage of Pearl's graph theory approach to causal reasoning, as many of the reviewers of prepublication drafts of the fourth edition have also noted, is both easy to understand and comprehensive. It's so good, he ought to get a prize for best in presentation! In this new edition, he takes us through causal mediation analysis, conditional process modeling, and confirmatory factor analysis with categorical indicators. Other additions to this masterpiece of pedagogy include insightful discussions of significance testing, the use of bootstrap estimation, and the principles of measurement theory. Although Rex suggests in his Introduction that no single book can cover all of SEM, his book is about as thorough as they come. His didactic approach is refreshing and engaging, and the breadth and depth of material covered is simply impressive. As he notes and you will feel. Rex is a researcher talking to you as a fellow researcher, carefully explaining in conceptually driven terms the logic and principles that underlie the world of SEM. The wealth of examples provide entry points for researchers across a broad array of disciplines. This book will speak to you regardless of your field or specific area of expertise. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-1-4625-2334-4 978-1-4625-2335-1 978-1-4625-2300-9},
  keywords = {Statistical Analysis,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/TJFEYZ7G/2015-56948-000.html}
}

@article{kyriazosAppliedPsychometricsSample2018,
  title = {Applied {{Psychometrics}}: {{Sample Size}} and {{Sample Power Considerations}} in {{Factor Analysis}} ({{EFA}}, {{CFA}}) and {{SEM}} in {{General}}},
  shorttitle = {Applied {{Psychometrics}}},
  author = {Kyriazos, Theodoros},
  year = {2018},
  month = jan,
  journal = {Psychology},
  volume = {09},
  pages = {2207--2230},
  doi = {10.4236/psych.2018.98126}
}

@article{laiCorrectingUnreliabilityPartial2023,
  title = {Correcting for {{Unreliability}} and {{Partial Invariance}}: {{A Two-Stage Path Analysis Approach}}},
  shorttitle = {Correcting for {{Unreliability}} and {{Partial Invariance}}},
  author = {Lai, Mark H. C. and Tse, Winnie Wing-Yee and Zhang, Gengrui and Li, Yixiao and Hsiao, Yu-Yu},
  year = {2023},
  month = mar,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {30},
  number = {2},
  pages = {258--271},
  publisher = {{Routledge}},
  issn = {1070-5511},
  doi = {10.1080/10705511.2022.2125397},
  urldate = {2024-02-26},
  abstract = {In path analysis, using composite scores without adjustment for measurement unreliability and violations of factorial invariance across groups lead to biased estimates of path coefficients. Although joint modeling of measurement and structural models can theoretically yield consistent structural association estimates, estimating a model with many variables is often impractical in small samples. A viable alternative is two-stage path analysis (2S-PA), where researchers first obtain factor scores and the corresponding individual-specific reliability coefficients, and then use those factor scores to analyze structural associations while accounting for their unreliability. The current paper extends 2S-PA to also account for partial invariance. Two simulation studies show that 2S-PA outperforms joint modeling in terms of model convergence, the efficiency of structural parameter estimation, and confidence interval coverage, especially in small samples and with categorical indicators. We illustrate 2S-PA by reanalyzing data from a multiethnic study that predicts drinking problems using college-related alcohol beliefs.},
  keywords = {Factor scores,measurement error,partial factorial invariance,reliability adjustment,two-stage path analysis},
  file = {/Users/jimmy_z/Zotero/storage/DC9KP982/Lai et al. - 2023 - Correcting for Unreliability and Partial Invarianc.pdf}
}

@article{laiTwostagePathAnalysis2022a,
  title = {Two-Stage Path Analysis with Definition Variables: {{An}} Alternative Framework to Account for Measurement Error},
  shorttitle = {Two-Stage Path Analysis with Definition Variables},
  author = {Lai, Mark H. C. and Hsiao, Yu-Yu},
  year = {2022},
  journal = {Psychological Methods},
  volume = {27},
  number = {4},
  pages = {568--588},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1463},
  doi = {10.1037/met0000410},
  abstract = {When estimating path coefficients among psychological constructs measured with error, structural equation modeling (SEM), which simultaneously estimates the measurement and structural parameters, is generally regarded as the gold standard. In practice, however, researchers usually first compute composite scores or factor scores, and use those as observed variables in a path analysis, for purposes of simplifying the model or avoiding model convergence issues. Whereas recent approaches, such as reliability adjustment methods and factor score regression, has been proposed to mitigate the bias induced by ignoring measurement error in composite/factor scores with continuous indicators, those approaches are not yet applicable to models with categorical indicators. In this article, we introduce the two-stage path analysis (2S-PA) with definition variables as a general framework for path modeling to handle categorical indicators, in which estimation of factor scores and path coefficients are separated. It thus allows for different estimation methods in the measurement and the structural path models and easier diagnoses of violations of model assumptions. We conducted three simulation studies, ranging from latent regression to mediation analysis with categorical indicators, and showed that 2S-PA generally produced similar estimates to those using SEM in large samples, but gave better convergence rates, less standard error bias, and better control of Type I error rates in small samples. We illustrate 2S-PA using data from a national data set, and show how researchers can implement it in Mplus and OpenMx. Possible extensions and future directions of 2S-PA are discussed. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Adjustment,Error Analysis,Error of Measurement,Estimation,Measurement,Path Analysis,Simulation,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/HGBMZNAU/2022-12378-001.html}
}

@article{linStructuralEquationModels2010b,
  title = {Structural {{Equation Models}} of {{Latent Interactions}}: {{Clarification}} of {{Orthogonalizing}} and {{Double-Mean-Centering Strategies}}},
  shorttitle = {Structural {{Equation Models}} of {{Latent Interactions}}},
  author = {Lin, Guan-Chyun and Wen, Zhonglin and Marsh, Herbert W. and Lin, Huey-Shyan},
  year = {2010},
  month = jul,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {17},
  number = {3},
  pages = {374--391},
  publisher = {{Routledge}},
  issn = {1070-5511},
  doi = {10.1080/10705511.2010.488999},
  urldate = {2024-02-26},
  abstract = {The purpose of this investigation is to compare a new (double-mean-centering) strategy to estimating latent interactions in structural equation models with the (single) mean-centering strategy (Marsh, Wen, \& Hau, 2004, 2006) and the orthogonalizing strategy (Little, Bovaird, \& Widaman, 2006; Marsh et al., 2007). A key benefit of the orthogonalizing strategy is that it eliminated the need to estimate a mean structure as required by the mean-centering strategy, but required a potentially cumbersome 2-step estimation procedure. In contrast, the double-mean-centering strategy eliminates both the need for the mean structure and the cumbersome 2-stage estimation procedure. Furthermore, although the orthogonalizing and double-mean-centering strategies are equivalent when all indicators are normally distributed, the double-mean-centering strategy is superior when this normality assumption is violated. In summary, we recommend that applied researchers wanting to estimate latent interaction effects use the double-mean-centering strategy instead of either the single-mean-centering or orthogonalizing strategies, thus allowing them to ignore the cumbersome mean structure.},
  file = {/Users/jimmy_z/Zotero/storage/ZTGIL5E9/Lin et al. - 2010 - Structural Equation Models of Latent Interactions.pdf}
}

@article{mackinnonHowWhomMediation2008a,
  title = {How and for Whom? {{Mediation}} and Moderation in Health Psychology},
  shorttitle = {How and for Whom?},
  author = {MacKinnon, David P. and Luecken, Linda J.},
  year = {2008},
  month = mar,
  journal = {Health Psychol},
  volume = {27},
  number = {2S},
  pages = {S99-S100},
  issn = {1930-7810},
  doi = {10.1037/0278-6133.27.2(Suppl.).S99},
  abstract = {Health psychology is maturing to include both major studies relating IVs to DVs as well as in-depth investigation of how these relations occur and for whom. These analyses reflect the richness of data collected in investigations of health and hold the promise of uncovering important pathways by which psychological factors influence health. From a methodological standpoint, investigation of mediation and moderation represents how a third variable may be incorporated in statistical analyses to uncover underlying mechanisms, differing effects on unique populations, or conditions under which an effect may be pronounced or diminished. Often the addition of these measures to research projects costs very little, but offers tremendous potential to yield detailed information critical to the advancement of theory and practice in health psychology.},
  langid = {english},
  pmcid = {PMC2821200},
  pmid = {18377161},
  keywords = {Behavioral Medicine,Humans,Mental Disorders},
  file = {/Users/jimmy_z/Zotero/storage/J2NL9Q42/MacKinnon and Luecken - 2008 - How and for whom Mediation and moderation in heal.pdf}
}

@article{marshStructuralEquationModels2004a,
  title = {Structural Equation Models of Latent Interactions: Evaluation of Alternative Estimation Strategies and Indicator Construction},
  shorttitle = {Structural Equation Models of Latent Interactions},
  author = {Marsh, Herbert W. and Wen, Zhonglin and Hau, Kit-Tai},
  year = {2004},
  month = sep,
  journal = {Psychol Methods},
  volume = {9},
  number = {3},
  pages = {275--300},
  issn = {1082-989X},
  doi = {10.1037/1082-989X.9.3.275},
  abstract = {Interactions between (multiple indicator) latent variables are rarely used because of implementation complexity and competing strategies. Based on 4 simulation studies, the traditional constrained approach performed more poorly than did 3 new approaches--unconstrained, generalized appended product indicator, and quasi-maximum-likelihood (QML). The authors' new unconstrained approach was easiest to apply. All 4 approaches were relatively unbiased for normally distributed indicators, but the constrained and QML approaches were more biased for nonnormal data; the size and direction of the bias varied with the distribution but not with the sample size. QML had more power, but this advantage was qualified by consistently higher Type I error rates. The authors also compared general strategies for defining product indicators to represent the latent interaction factor.},
  langid = {english},
  pmid = {15355150},
  keywords = {Analysis of Variance,Humans,Likelihood Functions,Mathematical Computing,Models Statistical,Nonlinear Dynamics,Psychology Experimental,Software}
}

@article{maslowskyEstimatingInterpretingLatent2015a,
  title = {Estimating and Interpreting Latent Variable Interactions: {{A}} Tutorial for Applying the Latent Moderated Structural Equations Method},
  shorttitle = {Estimating and Interpreting Latent Variable Interactions},
  author = {Maslowsky, Julie and Jager, Justin and Hemken, Douglas},
  year = {2015},
  month = jan,
  journal = {Int J Behav Dev},
  volume = {39},
  number = {1},
  pages = {87--96},
  issn = {0165-0254},
  doi = {10.1177/0165025414552301},
  urldate = {2024-02-26},
  abstract = {Latent variables are common in psychological research. Research questions involving the interaction of two variables are likewise quite common. Methods for estimating and interpreting interactions between latent variables within a structural equation modeling framework have recently become available. The latent moderated structural equations (LMS) method is one that is built into Mplus software. The potential utility of this method is limited by the fact that the models do not produce traditional model fit indices, standardized coefficients, or effect sizes for the latent interaction, which renders model fitting and interpretation of the latent variable interaction difficult. This article compiles state-of-the-science techniques for assessing LMS model fit, obtaining standardized coefficients, and determining the size of the latent interaction effect in order to create a tutorial for new users of LMS models. The recommended sequence of model estimation and interpretation is demonstrated via a substantive example and a Monte Carlo simulation. Finally, extensions of this method are discussed, such as estimating quadratic effects of latent factors and interactions between latent slope and intercept factors, which hold significant potential for testing and advancing developmental theories.},
  pmcid = {PMC4606468},
  pmid = {26478643},
  file = {/Users/jimmy_z/Zotero/storage/WQRWCJJ8/Maslowsky et al. - 2015 - Estimating and interpreting latent variable intera.pdf}
}

@article{mcdonaldTheoreticalFoundationsPrincipal1970,
  title = {The {{Theoretical Foundations}} of {{Principal Factor Analysis}}, {{Canonical Factor Analysis}}, and {{Alpha Factor Analysis}}},
  author = {McDonald, Roderick P.},
  year = {1970},
  journal = {British Journal of Mathematical and Statistical Psychology},
  volume = {23},
  number = {1},
  pages = {1--21},
  issn = {2044-8317},
  doi = {10.1111/j.2044-8317.1970.tb00432.x},
  urldate = {2024-02-26},
  abstract = {It is shown that PFA, CFA and AFA are particular cases of a scale-invariant factoring procedure based on variance ratios of certain weighted combinations of variables. Standard derivations in the literature are shown, in contrast, to have unsatisfactory features. It is suggested that the choice between PFA, CFA and AFA involves relatively independent choices of features of each, and that in most cases CFA is to be preferred.},
  copyright = {1970 The British Psychological Society},
  langid = {english}
}

@article{moulderComparisonMethodsEstimating2002a,
  title = {Comparison of Methods for Estimating and Testing Latent Variable Interactions},
  author = {Moulder, Bradley C. and Algina, James},
  year = {2002},
  journal = {Structural Equation Modeling},
  volume = {9},
  number = {1},
  pages = {1--19},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {1532-8007},
  doi = {10.1207/S15328007SEM0901_1},
  abstract = {Structural equation modeling methods for estimating and testing hypotheses about an interaction between continuous variables were investigated. The methods were (1) K. A. Bollen's (1996) 2-stage least squares (TSLS) method, R. A. Ping's (1996) 2-step maximum likelihood (ML) method, and J. Jaccard and C. K. Wan's (1995) ML method for the Kenny{\textendash}Judd model (D. A. Kenny and C. M. Judd, 1984); (2) a 2-step ML procedure and ML estimation of the J{\"o}reskog{\textendash}Yang model (K. G. J{\"o}reskog and F. Yang 1996); and (3) ML estimation of a revised J{\"o}reskog{\textendash}Yang model. The TSLS procedure exhibited more bias and lower power than the other methods. Under ML estimation of the J{\"o}reskog{\textendash}Yang model, Type I error rates were not well controlled when robust standard errors were used. Among the remaining procedures, the Jaccard{\textendash}Wan procedure and ML estimation of the revised J{\"o}reskog{\textendash}Yang procedure were most effective, with the latter having some small advantages over the former. A technical description of the simulation is appended. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Empirical Methods,Estimation,Latent Variables,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/CQ9EEGXS/2002-10162-001.html}
}

@article{muellerStructuralEquationModeling1997a,
  title = {Structural Equation Modeling: {{Back}} to Basics},
  shorttitle = {Structural Equation Modeling},
  author = {Mueller, Ralph O.},
  year = {1997},
  journal = {Structural Equation Modeling},
  volume = {4},
  number = {4},
  pages = {353--369},
  publisher = {{Lawrence Erlbaum}},
  address = {{US}},
  issn = {1532-8007},
  doi = {10.1080/10705519709540081},
  abstract = {Major technological advances incorporated into structural equation modeling (SEM) computer programs now make it possible for practitioners who are basically unfamiliar with the purposes and limitations of SEM to use this tool within their research contexts. The quest to simplify the data analysis step in the research process has{\textemdash}at least with regard to SEM{\textemdash}created a situation that allows practitioners to apply SEM but forgetting, knowingly ignoring, or most dangerously, being ignorant of some basic philosophical and statistical issues that must be addressed before sound SEM analyses should be conducted. This article focuses on some of the almost forgotten topics taken here from each step in the SEM process: model conceptualization, identification and parameter estimation, and data-model fit assessment and model modification. The main objective is to raise awareness among researchers new to SEM of a few basic but key philosophical and statistical issues. These should be addressed before launching into any one of the new generation of SEM software packages and being led astray by the seemingly irresistible temptation to prematurely start "playing" with the data. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Experimentation,Statistical Analysis,Statistical Data,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/RXTF6LBE/1998-00937-005.html}
}

@article{muthenHowUseMonte2002,
  title = {How to {{Use}} a {{Monte Carlo Study}} to {{Decide}} on {{Sample Size}} and {{Determine Power}}},
  author = {Muth{\'e}n, Linda K. and Muth{\'e}n, Bengt O.},
  year = {2002},
  month = oct,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {9},
  number = {4},
  pages = {599--620},
  publisher = {{Routledge}},
  issn = {1070-5511},
  doi = {10.1207/S15328007SEM0904_8},
  urldate = {2024-02-26},
  abstract = {A common question asked by researchers is, "What sample size do I need for my study?" Over the years, several rules of thumb have been proposed. In reality there is no rule of thumb that applies to all situations. The sample size needed for a study depends on many factors, including the size of the model, distribution of the variables, amount of missing data, reliability of the variables, and strength of the relations among the variables. The purpose of this article is to demonstrate how substantive researchers can use a Monte Carlo study to decide on sample size and determine power. Two models are used as examples, a confirmatory factor analysis (CFA) model and a growth model. The analyses are carried out using the Mplus program (Muth{\'e}n\& Muth{\'e}n 1998).},
  file = {/Users/jimmy_z/Zotero/storage/LNT33RLJ/Muthén and Muthén - 2002 - How to Use a Monte Carlo Study to Decide on Sample.pdf}
}

@article{radloffCESDScaleSelfReport1977b,
  title = {The {{CES-D Scale}}: {{A Self-Report Depression Scale}} for {{Research}} in the {{General Population}}},
  shorttitle = {The {{CES-D Scale}}},
  author = {Radloff, Lenore Sawyer},
  year = {1977},
  month = jun,
  journal = {Applied Psychological Measurement},
  volume = {1},
  number = {3},
  pages = {385--401},
  publisher = {{SAGE Publications Inc}},
  issn = {0146-6216},
  doi = {10.1177/014662167700100306},
  urldate = {2024-02-26},
  abstract = {The CES-D scale is a short self-report scale designed to measure depressive symptomatology in the general population. The items of the scale are symptoms associated with depression which have been used in previously validated longer scales. The new scale was tested in household interview surveys and in psychiatric settings. It was found to have very high internal consistency and adequate test- retest repeatability. Validity was established by pat terns of correlations with other self-report measures, by correlations with clinical ratings of depression, and by relationships with other variables which support its construct validity. Reliability, validity, and factor structure were similar across a wide variety of demographic characteristics in the general population samples tested. The scale should be a useful tool for epidemiologic studies of de pression.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/LIYJE2B9/Radloff - 1977 - The CES-D Scale A Self-Report Depression Scale fo.pdf}
}

@article{raykovEstimationCompositeReliability1997,
  title = {Estimation of Composite Reliability for Congeneric Measures},
  author = {Raykov, Tenko},
  year = {1997},
  journal = {Applied Psychological Measurement},
  volume = {21},
  number = {2},
  pages = {173--184},
  publisher = {{Sage Publications}},
  address = {{US}},
  issn = {1552-3497},
  doi = {10.1177/01466216970212006},
  abstract = {A structural equation model is described that permits estimation of the reliability index and coefficient of a composite test for congeneric measures. The method is also helpful in exploring the factorial structure of an item set, and its use in scale reliability estimation and development is illustrated. The estimator of composite reliability it yields does not possess the general underestimation property of Cronbach's coefficient {$\alpha$}. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Statistical Correlation,Statistical Estimation,Statistical Reliability,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/PD425XLS/1998-02976-006.html}
}

@article{rousseeuwRobustStatisticsOutlier2011,
  title = {Robust Statistics for Outlier Detection},
  author = {Rousseeuw, Peter J. and Hubert, Mia},
  year = {2011},
  journal = {WIREs Data Mining and Knowledge Discovery},
  volume = {1},
  number = {1},
  pages = {73--79},
  issn = {1942-4795},
  doi = {10.1002/widm.2},
  urldate = {2024-02-26},
  abstract = {When analyzing data, outlying observations cause problems because they may strongly influence the result. Robust statistics aims at detecting the outliers by searching for the model fitted by the majority of the data. We present an overview of several robust methods and outlier detection tools. We discuss robust procedures for univariate, low-dimensional, and high-dimensional data such as estimation of location and scatter, linear regression, principal component analysis, and classification. {\textcopyright} 2011 John Wiley \& Sons, Inc. WIREs Data Mining Knowl Discov 2011 1 73-79 DOI: 10.1002/widm.2 This article is categorized under: Algorithmic Development {$>$} Biological Data Mining Algorithmic Development {$>$} Spatial and Temporal Data Mining Application Areas {$>$} Health Care Technologies {$>$} Structure Discovery and Clustering},
  copyright = {Copyright {\textcopyright} 2011 John Wiley \& Sons, Inc.},
  langid = {english}
}

@article{schoemannTestingInterpretingLatent2021,
  title = {Testing and {{Interpreting Latent Variable Interactions Using}} the {{semTools Package}}},
  author = {Schoemann, Alexander M. and Jorgensen, Terrence D.},
  year = {2021},
  month = sep,
  journal = {Psych},
  volume = {3},
  number = {3},
  pages = {322--335},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2624-8611},
  doi = {10.3390/psych3030024},
  urldate = {2024-02-26},
  abstract = {Examining interactions among predictors is an important part of a developing research program. Estimating interactions using latent variables provides additional power to detect effects over testing interactions in regression. However, when predictors are modeled as latent variables, estimating and testing interactions requires additional steps beyond the models used for regression. We review methods of estimating and testing latent variable interactions with a focus on product indicator methods. Product indicator methods of examining latent interactions provide an accurate method to estimate and test latent interactions and can be implemented in any latent variable modeling software package. Significant latent interactions require additional steps (plotting and probing) to interpret interaction effects. We demonstrate how these methods can be easily implemented using functions in the semTools package with models fit using the lavaan package in R, and we illustrate how these methods work using an applied example concerning teacher stress and testing.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {interactions,latent variable,moderation,structural equation modeling},
  file = {/Users/jimmy_z/Zotero/storage/WHXNM2CP/Schoemann and Jorgensen - 2021 - Testing and Interpreting Latent Variable Interacti.pdf}
}

@article{steinmetzThreeApproachesEstimate2011a,
  title = {Three {{Approaches}} to {{Estimate Latent Interaction Effects}}: {{Intention}} and {{Perceived Behavioral Control}} in the {{Theory}} of {{Planned Behavior}}},
  shorttitle = {Three {{Approaches}} to {{Estimate Latent Interaction Effects}}},
  author = {Steinmetz, Holger and Davidov, Eldad and Schmidt, Peter},
  year = {2011},
  month = apr,
  journal = {Methodological Innovations Online},
  volume = {6},
  number = {1},
  pages = {95--110},
  publisher = {{SAGE Publications}},
  issn = {1748-0612},
  doi = {10.4256/mio.2010.0030},
  urldate = {2024-02-26},
  abstract = {Interaction effects between explanatory constructs are an important part of many social theories. Analyses of interaction effects between variables using regression techniques have low power because they do not control for measurement errors. Therefore, latent interaction modeling using structural equation modeling (SEM) has been proposed as a better alternative to test for interaction effects. In contrast to traditional and complicated ?constrained? SEM approaches, two recent developments, the unconstrained approach and the residual centering approach, are especially attractive for applied researchers as they are much easier to implement. However, applied researchers still seem to be unsure about how to apply these approaches. In this study, we illustrate the use of the unconstrained and the residual centering approach and compare these approaches with the constrained approach of Algina and Moulder (2001) using data from a field study of 1,442 students. Theoretical background is the theory of planned behavior (Ajzen, 1991) in which we test the proposed interaction between an individual's intention to perform a behavior and perceived behavioral control (PBC) on behavior. The illustration should assist researchers interested in testing interaction effects using structural equation modeling.},
  file = {/Users/jimmy_z/Zotero/storage/4I7HIEVP/Steinmetz et al. - 2011 - Three Approaches to Estimate Latent Interaction Ef.pdf}
}

@article{tenbergeGreatestLowerBound2004,
  title = {The Greatest Lower Bound to the Reliability of a Test and the Hypothesis of Unidimensionality},
  author = {Ten Berge, Jos M. F. and So{\v c}an, Gregor},
  year = {2004},
  month = dec,
  journal = {Psychometrika},
  volume = {69},
  number = {4},
  pages = {613--625},
  issn = {1860-0980},
  doi = {10.1007/BF02289858},
  urldate = {2024-02-26},
  abstract = {To assess the reliability of congeneric tests, specifically designed reliability measures have been proposed. This paper emphasizes that such measures rely on a unidimensionality hypothesis, which can neither be confirmed nor rejected when there are only three test parts, and will invariably be rejected when there are more than three test parts. Jackson and Agunwamba's (1977) greatest lower bound to reliability is proposed instead. Although this bound has a reputation for overestimating the population value when the sample size is small, this is no reason to prefer the unidimensionality-based reliability. Firstly, the sampling bias problem of the glb does not play a role when the number of test parts is small, as is often the case with congeneric measures. Secondly, glb and unidimensionality based reliability are often equal when there are three test parts, and when there are more test parts, their numerical values are still very similar. To the extent that the bias problem of the greatest lower bound does play a role, unidimensionality-based reliability is equally affected. Although unidimensionality and reliability are often thought of as unrelated, this paper shows that, from at least two perspectives, they act as antagonistic concepts. A measure, based on the same framework that led to the greatest lower bound, is discussed for assessing how close is a set of variables to unidimensionality. It is the percentage of common variance that can be explained by a single factor. An empirical example is given to demonstrate the main points of the paper.},
  langid = {english},
  keywords = {congeneric test,Reliability,unidimensionality of a test}
}

@article{wuComparisonStrategiesForming2013,
  title = {A {{Comparison}} of {{Strategies}} for {{Forming Product Indicators}} for {{Unequal Numbers}} of {{Items}} in {{Structural Equation Models}} of {{Latent Interactions}}},
  author = {Wu, Yan and Wen, Zhonglin and Marsh, Herb and Hau, Kit-Tai},
  year = {2013},
  month = oct,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {20},
  pages = {551--567},
  doi = {10.1080/10705511.2013.824772},
  abstract = {This Monte Carlo simulation study investigated different strategies for forming product indicators for the unconstrained approach in analyzing latent interaction models when the exogenous factors are measured by unequal numbers of indicators under both normal and nonnormal conditions. Product indicators were created by (a) multiplying parcels of the larger scale by items of the smaller scale, and (b) matching items according to reliability to create several product indicators, ignoring those items with lower reliability. Two scaling approaches were compared where parceling was not involved: (a) fixing the factor variances, and (b) fixing 1 loading to 1 for each factor. The unconstrained approach was compared with the latent moderated structural equations (LMS) approach. Results showed that under normal conditions, the LMS approach was preferred because the biases of its interaction estimates and associated standard errors were generally smaller, and its power was higher than that of the unconstrained approach. Under nonnormal conditions, however, the unconstrained approach was generally more robust than the LMS approach. It is recommended to form product indicators by using items with higher reliability (rather than parceling) in the matching and then to specify the model by fixing 1 loading of each factor to unity when adopting the unconstrained approach.}
}

